<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Universe OpenAstronomy (Posts by pkj-m)</title><link>http://openastronomy.org/Universe_OA/</link><description></description><atom:link href="http://openastronomy.org/Universe_OA/authors/pkj-m.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><lastBuildDate>Sun, 15 Dec 2024 01:24:44 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Google Summer of Code - The End!</title><link>http://openastronomy.org/Universe_OA/posts/2020/08/20200827_0614_pkj-m/</link><dc:creator>pkj-m</dc:creator><description>&lt;p&gt;Hello everyone! It has been a while since my last blog, and for a good reason. The past few weeks have been quite productive, and I thought it might be a good idea to present one final report of the work that I did over this past month instead of breaking it into subparts. With this blog, I will also be marking the end of my journey through the Google Summer of Code program. This blog will talk about some of the changes that the work I did as a part of GSoC brought to RADIS, and how you, the user can and will benefit from it.&lt;/p&gt;

&lt;p&gt;In my last blog, I briefly mentioned what I was planning to do with the GPU code and how to integrate it with RADIS. The current RADIS code performs calculation of spectra at thermal equilibrium (and even in non-equilibrium conditions) in primarily two ways:&lt;/p&gt;
&lt;!-- TEASER_END --&gt;

&lt;ol&gt;
&lt;li&gt;by defining a &lt;code class="language-plaintext highlighter-rouge"&gt;SpectrumFactory&lt;/code&gt; object, and then calling the method &lt;code class="language-plaintext highlighter-rouge"&gt;sf.eq_spectrum(Tgas=T)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;by passing the necessary parameters in the method &lt;code class="language-plaintext highlighter-rouge"&gt;calc_spectrum&lt;/code&gt;, which returns a Spectrum object directly&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;In our attempt to add support for GPU accelerated spectrum calculation, we wanted to keep the interface as similar to the original one as possible. Thus, the new method which we introduced to calculate the spectrum using GPU was naturally called &lt;code class="language-plaintext highlighter-rouge"&gt;eq_spectrum_gpu&lt;/code&gt;. The &lt;code class="language-plaintext highlighter-rouge"&gt;calc_spectrum&lt;/code&gt; method, which is actually a wrapper that makes of the &lt;code class="language-plaintext highlighter-rouge"&gt;eq_spectrum&lt;/code&gt; method underneath, was also modified and a new parameter called &lt;code class="language-plaintext highlighter-rouge"&gt;mode&lt;/code&gt; was added. Depending on what the value of &lt;code class="language-plaintext highlighter-rouge"&gt;mode&lt;/code&gt; is, the calculation of spectrum could be performed either on the GPU or on the CPU.&lt;/p&gt;

&lt;p&gt;Now coming to the implementation of &lt;code class="language-plaintext highlighter-rouge"&gt;eq_spectrum_gpu&lt;/code&gt;, I tried to keep the structure of the code as similar to the current CPU implementation as possible. What it meant was that the preprocessing done was in a way quite similar to the CPU version of the method. The difference actually came in during the broadening step. Initially our implementation was different from the CPU version when it came to loading the data, primarily because the data being loaded in the GPU method was in the ‘npy’ format. This made it necessary to implement another method for loading this data, as the data loader in RADIS did not support npy files. While implementing this was not difficult, it was not seen as a very good design decision, as this type of loading and handling of data was very isolated and not compatible with the rest of RADIS’ features. Therefore, ultimately it was to keep this mpy2df method as an additional, helper method, and instead of using it as the primary source of data, we use the dataframe which RADIS already generates instead. This allowed us to keep things compatible with the current implementation to a great extent, and the only downside, if it can be considered that, was the need to now compute the parameters before the spectrum is calculated, which in case of npy files were already present for us. This however, was virtually a non-problem since this step was not even remotely close to the bottleneck, and the flexiblity it provided in terms of loading and preprocessing data outweighed this extra computation easily. At this point we had the data loaded in memory, either through the legacy data loader using the dataframe, or by passing the location of the npy files in the system and loading them directly. After this, we had to pass this data to the GPU module. The GPU module, titled py_cuFFS, is actually a Cython file with some CuPy, which serves as the complete host+device code for the computation of the spectra. Using Cython over Python allows us to compile the module prior to using it, which gives an added performance boost. The compilation however, is a machine-specific process and cannot have a single-file-handles-all kind of implementation. Thus, instead of sharing the binary file with the users, we instead share the source code. Whenever the user calls the GPU accelerated methods on their system for the first time, RADIS automatically compiles the source code into the binary, which then gets compiled according to the system environment of the user. Now, the compiled binary is imported by RADIS, and the input parameters such as the temperature, pressure and the partition function are passed on to the GPU.&lt;/p&gt;

&lt;p&gt;The GPU module returns the spectrum to RADIS, which then computes other quantities, such as the absorbance and transmittance from this. From this stage onwards the code for &lt;code class="language-plaintext highlighter-rouge"&gt;eq_spectrum&lt;/code&gt; and &lt;code class="language-plaintext highlighter-rouge"&gt;eq_spectrum_gpu&lt;/code&gt; is identical. Both the methods update the metainformation such as the calculation time, number of lines calculated, etc. In order to read more about the GPU module and how to use it, I highly recommend the users to go through the &lt;a href="https://radis.readthedocs.io/en/latest/lbl/gpu.html"&gt;documentation&lt;/a&gt; which has not just examples but also a guide on how to setup your system in order to make use of these GPU accelerated methods. If you’d just like to observe for now, I would recommend going through this &lt;a href="https://github.com/radis/radis-benchmark/blob/master/TEST1.ipynb"&gt;notebook&lt;/a&gt; on radis-benchmark which gives an example of how to use these methods to calculate the spectrum on the GPU, and an impressive speed test between the GPU and the CPU methods when calculating spectra with 5M lines.&lt;/p&gt;

&lt;p&gt;This wraps up my journey with RADIS a Google Summer of Code participant. It has been an excellent experience with a great deal of learning involved. I had prior experience of working with CUDA for deep learning pipelines but this was a completely new domain. In addition to the programming itself, I got exposed to the world of spectroscopy which was also very interesting. While my contribution to RADIS under the GSoC aegis comes to an end with this blog, I am still really excited to be a part of RADIS as it grows further. My GSoC project started what would hopefully end with a completely GPU-accelerated RADIS, but there is still plenty of work before we can say that. My GSoC project implemented the thermal equilibrium variant of the spectrum calculation method, but we still need to work on non-equilibrium methods. In addition, we also need to modify the GPU code itself to allow support for weighted air- and self-collision factors, among other things. There’s a lot to do, but I think we’ve had a good start. Most importantly, I am happy with the way I am ending this project. The code is ready and we have proper guide, documentation and examples in place so any new user can easily try this feature out themselves! I am really excited about the feedback and what users have to say about this GPU implementation. Finally, none of this would have been possible without the constant support and assistance from my amazing mentors, Erwan ( &lt;a href="https://github.com/erwanp"&gt;@erwanp&lt;/a&gt; ) and Dirk ( &lt;a href="https://github.com/dcmvdbekerom/"&gt;@dcmvdbekerom&lt;/a&gt; ). It would be hard to understate the contribution they’ve made to my project, helping constantly not just with the code but also in designing and planning the next steps. My lack of knowledge in the domain of spectroscopy was a huge pain at times which led to extremely long periods of slow progress due to painful debugging, but they always took out time from their packed schedules to help me out. Once again, thank you! It has been a wonderful experience, working with RADIS and I am really excited to see what how RADIS grows in the future!&lt;/p&gt;

&lt;p&gt;P.S. for anyone who’d like to go through the code of the project, you can find the pull request here: https://github.com/radis/radis/pull/117. And more importantly, if you’d like to know more, want to contribute, or just talk to the team, feel free to join us at our slack &lt;a href="https://radis.github.io/slack-invite/"&gt;here&lt;/a&gt;.&lt;/p&gt;</description><category>radis</category><guid>http://openastronomy.org/Universe_OA/posts/2020/08/20200827_0614_pkj-m/</guid><pubDate>Thu, 27 Aug 2020 05:14:12 GMT</pubDate></item><item><title>Google Summer of Code - Blog #4!</title><link>http://openastronomy.org/Universe_OA/posts/2020/07/20200728_1823_pkj-m/</link><dc:creator>pkj-m</dc:creator><description>&lt;p&gt;Hello! Welcome to the latest blog post in my Google Summer of Code series. With this blog, we’ll marking the end of the second phase of evaluations! Additionally, this blog is going to be a little different from all the previous ones as we finally start to work and discuss about Python and the actual RADIS code base.&lt;/p&gt;

&lt;p&gt;Honestly, I am actually really glad that we’re finally at this stage. The monotonity of Cython and working on the same, huge Cython+CuPy file with more than a thousand lines of code was getting very frustrating :P&lt;/p&gt;
&lt;!-- TEASER_END --&gt;

&lt;p&gt;In this blog, I shall be discussing more about the way we will integrate the GPU code with RADIS. But before we do that, let us first understand how RADIS handles this part right now, performing computations purely on the CPU. In order to compute the spectra of a molecule, we make use of module defined in RADIS known as &lt;code class="language-plaintext highlighter-rouge"&gt;Line-by-Line&lt;/code&gt; Module or LBL for short. This module contains numerous methods which are used for calculations of spectras. One of the most standard methods for computing the spectras is known as &lt;code class="language-plaintext highlighter-rouge"&gt;calc_spectrum&lt;/code&gt;, which takes in inputs such as the molecule, isotopes, temperature, pressure, waverange over which the spectra needs to be calculated (and many other depending on the user’s requirements) and returns the result in the form of &lt;code class="language-plaintext highlighter-rouge"&gt;Spectrum&lt;/code&gt; object which neatly packs the information in single object which can then be processed as needed. This is what the user sees when they use RADIS. However, for us to develop and contribute, we also need to understand what goes on under the hood when a method such as &lt;code class="language-plaintext highlighter-rouge"&gt;calc_spectrum&lt;/code&gt; is called.&lt;/p&gt;

&lt;p&gt;The first thing that occurs when &lt;code class="language-plaintext highlighter-rouge"&gt;calc_spectrum&lt;/code&gt; is called is the validation and conversion of physical quantities (such as temprature and pressure) into default units that are assumed in the rest of the code. This is followed by the instantiation of an object from the &lt;code class="language-plaintext highlighter-rouge"&gt;SpectrumFactory&lt;/code&gt; class, which will contain all the information about the spectrum to be computed. This is all standard, something that will happen each time &lt;code class="language-plaintext highlighter-rouge"&gt;calc_spectrum&lt;/code&gt; gets called. However, from here on, things start to get interesting as we look into the databank. Let us first understand what the purpose of a databank is: in order to compute a spectra for a specfic molecule, we need information about it. This could include data like line positions, line intensities, pressure-broadening parameters, etc. We don’t have to understand what each of these quantities mean or represent (to be honest, I don’t either) but the main idea we need to internalize is that we can’t compute a spectra without any information. So while it might be fair to say that a spectra can literally be generated from thin air, metaphorically that does not hold true.
This data, used to compute the spectra, can often be huge and therefore we try to avoid moving it around as much as possible. RADIS has implemented cache features in order to minimize the computations to be done on the raw databank. The important idea we need to focus on, is that once a databank has been loaded, we don’t have to load it once more if we ever call &lt;code class="language-plaintext highlighter-rouge"&gt;calc_spectrum&lt;/code&gt; again for the same data (with maybe different waverange, etc.) This is done using extra memory: the original data that is loaded in the memory is saved as a dataframe, and every call made to &lt;code class="language-plaintext highlighter-rouge"&gt;calc_spectrum&lt;/code&gt; first creates a copy of this data and works on it instead. This preserves the original dataset and allows us to use it again in case it is required, as the cost of the extra memory needed to save the copy. This was also the first problem I had to tackle: the GPU code we were going to use made use of &lt;code class="language-plaintext highlighter-rouge"&gt;npy&lt;/code&gt; formatted arrays to load the data, whereas RADIS was designed to load &lt;code class="language-plaintext highlighter-rouge"&gt;h5&lt;/code&gt; or &lt;code class="language-plaintext highlighter-rouge"&gt;par&lt;/code&gt; files. This meant I had to modify the databank loader RADIS used to support npy files. This was not a very significant problem however, as we could simply load the data separately instead of using the databank. The only issue with this approach would have been the repeated loading of data everytime the function call was made, but since we were using a small dataset, it wasn’t a significant issue and we decided to push it back and first focus on getting the GPU code to work with independent data being loaded.&lt;/p&gt;

&lt;p&gt;Once we had the data, the next step was to perform the computations. Now I won’t go into the details in this part since the mathematics behind these computations was something which: 1. I didn’t understand completely, and 2. I didn’t need to understand completely. Given my project already had a proof-of-concept code with the mathematics inplace, and my job was to make that code compatible with RADIS, I didn’t need to understand the nuances of it. I did go through the paper draft to understand the general idea behind the parallel approach we used, but I didn’t even try with the serial code since I had absolutely nothing to do with it. This mathematics was actually abstracted and encapsulated in another method &lt;code class="language-plaintext highlighter-rouge"&gt;eq_spectrum&lt;/code&gt;. Once this method finished execution, we would have the spectrum ready with all the information ready for the user. Within this method, there was one specific method that was of particular interest to us: &lt;code class="language-plaintext highlighter-rouge"&gt;_calc_broadening&lt;/code&gt;, responsible for the broadening step in the spectra calculation pipeline. This method was the bottleneck in the entire process, and the GPU code was primarily helping us speed up this particular portion of the process. My job here was to create another analogous method &lt;code class="language-plaintext highlighter-rouge"&gt;eq_spectrum_gpu&lt;/code&gt; which would do the exact same job as &lt;code class="language-plaintext highlighter-rouge"&gt;eq_spectrum&lt;/code&gt;, except instead of calling the sequence of serial methods to compute the spectra, I’d simply call the GPU code which was ready for us, and obtain the result. Some further processing of this result (which is computationally very inexpensive compared the rest of process), we have our spectra ready. It is a lot simpler and significantly easier than the CPU equivalent since we off-load the entire process to the Cython-compiled binaries and don’t have to worry about anything else. One problem I had with this (which is still not resolved as of writing this) is how do we fill in the missing information gaps in the Spectrum object, which in case of the CPU code were filled sequentially as the pipeline proceeded. Since our GPU code would only return the final result, I am not sure if we would be able to recover the preceding information bits which we didn’t obtain. Hopefully I’ll have the answer to it tomororrow when Erwan replies. That would pretty much finish my job here.&lt;/p&gt;

&lt;p&gt;However, another important bit of information that we’re skimming over is how we call the compiled binary file. This part is in fact what I will be working on over the coming week. The idea is that although right now I am using a simple binary file located in the same file to run the code, it is possible (and highly likely) that the same binary file will not work properly (or at all) in another system it is not meant for. As a consequence, the entire method might crash. In order to resolve this, we will be looking into placing the source code instead of the binary file in the RADIS codebase, and everytime a user needs to use the GPU version of &lt;code class="language-plaintext highlighter-rouge"&gt;calc_spectrum&lt;/code&gt;, the code will first, automatically, compile the Cython file on their system, obtain the binary file meant for their system, and use that instead. The details regarding the implementation of this bit are still not clear as it is something I will be working on next week!
The next blog will cover the implementation details about this runtime-compilation setup along with a discussion on what is next! Thank you!&lt;/p&gt;</description><category>radis</category><guid>http://openastronomy.org/Universe_OA/posts/2020/07/20200728_1823_pkj-m/</guid><pubDate>Tue, 28 Jul 2020 17:23:12 GMT</pubDate></item><item><title>Google Summer of Code - Blog #3!</title><link>http://openastronomy.org/Universe_OA/posts/2020/07/20200714_0804_pkj-m/</link><dc:creator>pkj-m</dc:creator><description>&lt;p&gt;Hey! Continuing from where we left off last time, in this blog I’ll be talking about the work I did in the period between 1st - 15th July. As I had mentioned in the previous blog, my primary task for this period was to get the Cython/CuPy version of our proof-of-work code to produce the correct output. I had initially expected the work to be relatively easy, as the output was already there; I simply had to check the logic part of the program to identify why it wasn’t correct. However, the work actually turned out to be a lot more painful that I’d have imagined. I had briefly touched upon this fact in the last blog as well, but the first thing I had to do in order to finish this task was to ensure that the debugging tools and methods were in place. This, fortunately, was one of the easier parts of the problem. The problem was two fold, and thus required 2 different solutions as well.
First, the loading of the dataset on to the RAM was a challenging task for my computer. I am not sure exactly why that was the case, but it certainly was nowhere as performant as the C++ code which did the same task of loading the exact same data in a relative breeze. I looked around the internet to understand what could possibly be slowing down the loading step so much, which was quite simply a single line : &lt;code class="language-plaintext highlighter-rouge"&gt;v0 = np.load(dir+path+'v0.npy')&lt;/code&gt;. The file itself was around 400MB, and there were a total of 8 of them, pushing the total memory required to around 3 GB. The solution to this problem was relatively straight forward, and felt almost as if it was hiding in plain sight when I did find it. The core idea is that when we try and load a numpy array the way I was doing without having declared the variable previously as a c-type, Cython quite naturally assumes it to be a pure Python variable and therefore fails to deliver the performance boost it promises on compilation. This however, was a trivial issue to resolve. All I had to leverage the advantage promised by Cython was to declare the numpy arrays prior to loading them with the datasets. This was done with a simple line &lt;code class="language-plaintext highlighter-rouge"&gt;cdef np.ndarray[dtype=np.float32_t, ndim=1] v0 = np.zeros(N_points, dtype=np.float32)&lt;/code&gt;. That was it! With just this single addition, the array was now a c-type variable and thus was processed significantly faster than the older pure numpy arrays. Unfortunately I didn’t benchmark the difference as I still have some things which I am not super confident about related to this part. I am not sure if it’s due to an observation bias or some other external factor, but I felt that the speed of loading the data itself varied quite significantly even with the same binaries. I am not sure if this is due to some caching/optimizations being done under the hood by the compiler itself, but whatever it is, certainly would make aimless benchmarking without controlling these external factors a futile exercise.
The second issue which I faced which was making debugging difficult was the inability of my GPU to automatically kill the Python/CuPy tasks once the program finished execution. I searched around stackoverflow and found that it is actually a rather common issue with CuPy. As a result, it also didn’t take a long time before I found a makeshift solution for this problem as well. All I had to do once the program had finished execution was to call some specific CuPy methods to free the memory, and it worked just fine! With these two issues sorted, I had a much better setup in place to try and debug the code without being forced to restart the computer or wait 10 minutes for the RAM to clear up everytime the program finished execution!&lt;/p&gt;
&lt;!-- TEASER_END --&gt;

&lt;p&gt;Now moving on to the actual issues in the code! It’d be an understatement to say the code wasn’t riddled with a number of bugs. As some of you might remember, I explained in the previous blog how we had decided to not worry about trying to fix variables into structs before passing and instead adopted a slightly different approach of using each attribute as an independent variable. While this wasn’t such a bad idea, and infact allowed me to proceed quite quickly, it was annoying with respect to how much had to be typed just to pass a single variable. Everytime you need to call the variable, you’d have to ensure the variable had been specified with the global identifier before being used. Naturally, all this led to a huge scope of facing some issues and I certainly did. After  writing the kernels and compiling the code, I tried to run the program for the first time. The initial few errors I faced were trivial bugs that were solved almost instantly. But the first major problem that I ran into was an IllegalMemoryAccess error that was thrown by CuPy/CUDA. As the name suggests, this was happening because at some place in my kernel, I was trying to access an address in the memory that just hadn’t been declared. The problem in debugging this issue was that I had no idea which memory load operation was throwing the error, neither the variable nor the line number. This proved very difficult to debug because of this reason, along with the fact that I simply couldn’t get the kernels to print anything on the terminal using CuPy. I was probably a few days into this problem before I approached my mentors to discuss about it. While my mentors were very helpful and went through the code and provided feedback on a lot of other aspects of the code which had room for improvement, none of their suggestions were aimed directly towards the problem itself. We had a few places we knew we could try to inspect and check if they’re the source, but it’d have been a difficult process. Fortunately, though, something really unexpected happened at this time. Dirk found out a way to get the structs to work in CuPy, as well as the syntax to save them in GPU’s constant memory. While this didn’t directly affect the kernel code itself, it did make the code a lot neater and easier to inspect. However, the biggest advantage wasn’t that! For some weird reason which I am still not sure of, the modification in the code to store variables under structs and saving the two constant structs in the constant memory somehow solved the illegal memory access!! I was so stunned the first time it happened. I had been banging my head against the wall for over a week because of that issue, and somehow making another adjustment in the code which I thought was completely unrelated to the issue resolved it instantly. The feeling was so satisfying it’s hard to put it in words!&lt;/p&gt;

&lt;p&gt;However, the battle was still not over. Although the code went on to execute till the end after this error was resolved, it still failed to produce the correct output. I was getting an output, an array which ideally should have been the spectrum produced according to the conditions specified and the data passed, but it just didn’t match with the output of the C++ program. More than just a mismatch in the values, it felt particularly bad since the values I was getting as the output were a mixed bunch of both positive and negative numbers, which especially didnt make any sense as the output was supposed to represent the intensity, so a negative value had no real physical meaning. Once again I was stuck in another long arduous cycle of trying to identify what’s going wrong in those 1000 lines of code. However, this time I was determined to solve it myself and thus started the debugging process in the most rudimentary manner possible. I decided to follow the execution of the program, one step at a time and print the values obtained till that step. Sounds pretty simple, doesn’t it? Except the problem was this: the valus that were being processed and passed on to the next methods in this sequence of steps weren’t separate primitive values like floats or ints, but instead arrays with more than 50,000 floats or at times, even millions of them. Thus while the idea was pretty simple, the execution was just as exhausting. I had to print the values not just for the Cython code I had written, but also for the C++ program at each step, since I didn’t have anything else to refer too. This was just as cumbersome as it sounds. After printing the thousands upon thousands of values in text files and saving them, I was also left with the task of checking them to see if they match or not. Again, since these were too many rows to compare directly, I had to write scripts in Python to do just that: load arrays with hundred thousand elements from text files, and compare them. While the process wasn’t difficult in itself, it was what people might call monotonous and extremely draining since each step took time and almost ironically, couldn’t be carried out in parallel as I just didn’t know at what stage the error creeped in. Thus, after hours and hours of executing the program, saving the file and comparing the values, I was able to narrow down my search to a single method in the huge file. Infact, I knew exactly where the error was. It was the output array from the first kernel, which we called &lt;code class="language-plaintext highlighter-rouge"&gt;host_params_h.DLM_d_in&lt;/code&gt;. Now that I knew where the error was, I was sure that the error originates from somewhere in the first kernel as it failed to produce the correct output. Thus, I once again started this whole process of comparing the variable values one at a time until I could see where the difference lies. However, this time the search failed to bring any results as literally every single input variable for the kernel was identical to the values that were being passed to the C++ kernel. There was no chance of the kernels behaving differently in the two programs as the code was literally the same for both. And with that I hit a dead-end. Again lost with no ideas left to pursue, I approached my mentors and they offered a lot of suggestions as to what might be going wrong, and once again it was something which they suggested that resolved this issue. Turns out, the array that we were using in the program, which was a three-dimensional numpy array, was not being read properly by the kernel. So as all you might know, even though we often use multidimensional arrays in our programs, the memory in the computer is arranged in a single dimension. Therefore, multidimensional arrays bring with them the question of how to store them in the memory. This exact idea was the logic behind the painpoint in my code. While numpy arrays that we defined in the Cython portion of our code was for all purposes normal 3D arrays which could be indexed using the standard arr[i][j][k] notation, under the hood things were being done in a different manner than we thought. However, once we realized that this was the source of the error, it was quite easy to resolve by simply specifying, during the declaration of the array,  the type of ordering we want for our elements in the memory. In numpy, there are two options for order, ‘C’ and ‘F’. C refers to the style in which C stores multidimensional arrays in memory, in a ‘row-major’ fashion while F refers to Fortran, which instead adopts the ‘column-major’ option. Now that this was over, I was expecting, as you might be expecting, that everyone was happy and working exactly the way we were expecting it to. But this problem was still far from over! I had successfully managed to get the values of &lt;code class="language-plaintext highlighter-rouge"&gt;host_params_h.DLM_D_in&lt;/code&gt; to match, and yet the final output didn’t match with the expected value. At this point I was extremely frustrated since the mismatch in the values meant that the error was being generated somewhere in the 10 odd lines of code that were left after the first kernel’s execution. Out of those few lines, a couple were function calls to the fourier transform libraries inbuilt in CuPy, and I was certain that couldn’t possibly be the source of error. The only possibility left was the second kernel call. However, unlike the first kernel, the second kernel was fairly straightforward and it wasn’t clear what could possibly be going wrong in those 15 lines or so. This also went on for a few more days until one day my mentor, Dirk, suggested that since we are so close to the final working code, that we do a live-collaborative coding session to fix the final problems and be done with this. I couldn’t have asked for more! For me who had been struggling with these last few annoying bugs for so long, Dirk offering to help me out over not just over text but on a video conference was a silver lining. We quickly decided on a date and were ready to squash those bugs. While we made some progress in the first hour or so, eventually we also hit a dead end where neither of us could figure out what could be going wrong. And then, with a stroke of luck that some might consider divine intervention ( :P ) the strange thought of trying to compute the FFT on the CPU came to our mind. It was something that we thought of due to pure desperation to do something, to check something. At that point we’d done everything we could think of to see where the bug came from but it was to no avail. I had absolutely zero expectations from the change in FFT that we were trying to accomplish, for all we did was change the processor on which the FFT was being computed. Instead of computing it on the GPU using CuPy, we did it directly on the CPU using Numpy. And once again, as the program executed and produced the correct shape on the plot produced in the output, we were left speechless. We had absolutely no idea what had happened. The change that we’d made a few moments ago was definitely the last thing I could have thought of as responsible for the bug, but somehow, that was it. But apart from the surprise, we were also happy and relieved to have finally identified the source of the error. It was either the forward FFT or the inverse FFT. Another hit and trial experiment narrowed it down further and we were sure that at this point, it was the forward FFT which was the source of error. However, we still couldn’t comprehend why that might be the case. We did a lot of googling, a lot of playing around with &lt;code class="language-plaintext highlighter-rouge"&gt;np.fft.rfft&lt;/code&gt; but it didn’t help. Even though we knew the problem was somewhere in the way the data was being read (as we’d previously noted during the other indexing issue), we didn’t know why or how it was that way. Effort to print the order of the array didn’t work as the numpy class apparently does not have an attribute called &lt;code class="language-plaintext highlighter-rouge"&gt;order&lt;/code&gt;, and instead it is something which can only be passed during the declaration. After possibly sitting there for maybe another hour or so, Dirk came up with something absolutely amazing. In order to check the way the data was being mapped to the memory without having something like &lt;code class="language-plaintext highlighter-rouge"&gt;order&lt;/code&gt; to print, Dirk found out and suggested the use of &lt;code class="language-plaintext highlighter-rouge"&gt;flags&lt;/code&gt;. Flags was infact the attribute we were looking for, containing all the information about the way the data was being mapped to the memory. A quick look at the flag from the output of the FFT confirmed our suspicions. The returned array was F-continous, but not C-continous. What this meant was that the data was being stored in a column major format, while the kernel had been written for C data. It was an easy issue to resolve once the error itself was clear and within a minute, after changing the indexing in the kernel body, we were done! The code compiled without any hiccups, the binaries ran without any issues and out came within a minute the plot I had been waiting for! It was a great moment to be very honest, seeing the work I had been doing for the past month or so finally working the way we’d always expected it to. With that, I finally had a working Python-compatible version of our code to produce spectra using GPUs.&lt;/p&gt;

&lt;p&gt;Now that we’re done with this part of the project, the upcoming weeks will be spent on making this work with RADIS. While the code, the way it is right now, is capable of calculating the spectra by itself without the need or support of any external code except the modules we use, it might not remain in such an independent form after its integration with RADIS is complete. I am not very certain about the details of this part of the project yet, but I will be having a meeting with my mentor, Erwan soon to discuss it. In the next blog, I think you guys can expect some discussion on the integration part of this project along with the details of how RADIS will start supporting GPU compatible methods! With that, I would like to conclude this blog! Disqus is always open for feedback and ofcourse, thanks for your time!&lt;/p&gt;</description><category>radis</category><guid>http://openastronomy.org/Universe_OA/posts/2020/07/20200714_0804_pkj-m/</guid><pubDate>Tue, 14 Jul 2020 07:04:56 GMT</pubDate></item><item><title>Google Summer of Code - Blog #2!</title><link>http://openastronomy.org/Universe_OA/posts/2020/06/20200629_2135_pkj-m/</link><dc:creator>pkj-m</dc:creator><description>&lt;p&gt;Hello! This blog marks the end of the first phase of Google Summer of Code. The journey so far has been challenging but also extremely rewarding. The knowledge gained as a by-product of the work I’ve been doing on my project so far is unbelievable, but more importantly has been a better, more pleasant experience compared to the traditional system of gaining knowledge by reading books and tutorials. In this blog, I will be summarising the work that I’ve been doing for the past 2 weeks, update the readers on my current position and give an idea of what lies ahead.&lt;/p&gt;

&lt;p&gt;As I discussed in my previous blog, the work for the first two weeks mostly involved using Cython to translate the host code into something which could be compiled to provide better performance. More importantly, apart from the Cython part, I had to also start working on porting the kernels from their pure CUDA C form into something which Python/Cython could also understand. While the actual work to do so did not take long or came across as very challenging, the most difficult part in the whole process, undeniably, was to get the two, Cython and CuPy to talk to one another.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;

&lt;p&gt;When I finished writing the previous blog, I was still left with quite a large volume of host code which was waiting to be converted to the Cython equivalent. Going through the previous blog, I’d like to make one correction in the part where I said I found Cython quite confusing. Infact, calling it a correction would not be correct. Instead, I should say that Cython isn’t actually all that difficult as I might have made it look like in the last blog. After a fair amount of reading and writing code in Cython, I think the developers of Cython have actually done an excellent job. After the initial barrier is crossed (and it happens fairly naturally), writing Cython code feels just as normal and second nature as pure Python code. Infact, I’d go so far as to claim that Cython feels more natural to me now than Python itself because of my previous experience in C++. This newly found familiarity allowed me to proceed quite quickly with this part of the project. The only problems that I encountered were: (1) the inter-conversion between arrays/vectors and pointers that we are used to in C++ is not possible in case of Cython, and this resulted in me being forced to make some slight changes in the host code, and (2) using structs in Cython isn’t as direct and straighforward as in C/C++. The reason behind this is the fact that Cython tries to estabilish relationships between C-type data structures and Python objects. While this is quite trivial for objects of types int, float, char, and even arrays to some extent, in case of structs this is nowhere near as easy. While I am sure there must have been some hacky way around this problem too, me and my mentors decided it is not something worth wasting time on, and thus we decided to bypass all structs and directly used each of their attributes as variables with the struct name attached as prefix, so &lt;code class="language-plaintext highlighter-rouge"&gt;host_params_h.shared_size&lt;/code&gt; became &lt;code class="language-plaintext highlighter-rouge"&gt;host_params_h_shared_size&lt;/code&gt;. While not the exact same thing, it allowed us to achieve the same objective without a lot of modifications to the code, either in terms of declaration or syntax. The only downside to this whole approach was that it made the code quite verbose, as instead of passing a single struct with 10 fields inside it, we were forced to pass 10 variables for each struct. This unique problem was further aggravated as we were using global variables instead of passing them around as arguments, and as every Python user would know, this meant adding the line &lt;code class="language-plaintext highlighter-rouge"&gt;global &amp;lt;varname&amp;gt;&lt;/code&gt; before every function body, which when done for every method and every variable, meant a lot of lines which could have been avoided. Apart from these two major issues and couple of minor problems here and there, the whole process was fairly straight forward. At the end of this step, I was left with a Cython file which compiled just fine, but didn’t really accomplish much. The key ingredient that was missing, was the very the heart of the project: the kernels.&lt;/p&gt;

&lt;p&gt;Kernel is actually nothing but a fancy word for the part of the code which actually executes on the GPU. Given the project title, it’d be fairly obvious that in our project, the kernels are actually where the magic happens. While this is not meant to discount the importance of the host (or the CPU code), the kernels are ulimately the part of the program which are responsible for the performance boosts that we observe. Kernels, atleast those which are meant to be executed on Nvidia’s GPUs, are usually written in a language known as CUDA C. This is a special language that is written on top of the original C language, but with extra set of features, classes and methods which provide us an abstracted interface to control various aspects of the program and the way it is implemented on the GPU, more so than a conventional serial algorithm meant to be implemented on the GPU. While using CUDA C is quite straightforward, especially with the large community support and well-written documentation, we unfortunately could not make use of that as we wanted something that was written and compatible with Python and things written on top of Python. Thus, after a lot of deliberation and discussion, my mentors and I agreed to use something known as CuPy to handle the CUDA C part of our code.  CuPy is an incredibly well-written module with neat documentation and decent community support, which made things a lot simple for us. However, more than anything, the biggest advantage of using CuPy was its RawModule method. The idea behind RawModule was to allow users who already have a CUDA C file written to do some specific task (us!) could simply re-use their code and get away with the whole problem of running kernels in Python very, very easily. Let me demonstrate it using an example and that would perhaps make things even more clear:&lt;/p&gt;

&lt;div class="language-python highlighter-rouge"&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight"&gt;&lt;code&gt;
&lt;span class="n"&gt;loaded_from_source&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;r'''
extern "C"{
...
__global__ void test_sum(const float* x1, const float* x2, float* y, \
unsigned int N)
{
unsigned int tid = blockDim.x * blockIdx.x + threadIdx.x;
if (tid &amp;lt; N)
{
y[tid] = x1[tid] + x2[tid];
}
}
}'''&lt;/span&gt;

&lt;span class="n"&gt;module&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cp&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;RawModule&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;code&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;loaded_from_source&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ker_sum&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;module&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;'test_sum'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;
&lt;span class="n"&gt;x1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cp&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;arange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;cp&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;x2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cp&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ones&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;cp&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cp&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;cp&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ker_sum&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;   &lt;span class="c1"&gt;# y = x1 + x2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;While the code looks fairly self-explanatory, I’ll give a quick runthrough anyway. The idea behind CuPy’s RawModule method, true to it’s name, is to allow the raw CUDA source to work with Python, which in our case is the string named &lt;code class="language-plaintext highlighter-rouge"&gt;loaded_from_source&lt;/code&gt;. Using RawModule, we process the string as a CUDA C source file, extract the relevant kernels from the file, &lt;code class="language-plaintext highlighter-rouge"&gt;test_sum&lt;/code&gt; in our case, and we’re done! The function is stored as &lt;code class="language-plaintext highlighter-rouge"&gt;ker_sum&lt;/code&gt; in Python, and is ready for use just like any other Python method. In order to keep the look and feel of the module as close to the original CUDA C source codes, even the way kernels are called is quite similar to how they’re called in C. The first two parameters, are the grid and block dimensions, and finally we follow through with the actual parameters to the kernel. Clearly, this allowed us to fast-track a lot of the kernel porting work, and quickly develop a Python version of our original proof-of-concept code.
However, like everything else, even this wasn’t going to work as easily as we’d initially expected. Instead, I faced a new challenge, which was the use of a struct written in the CUDA library, used for fast fourier trasforms, known as &lt;code class="language-plaintext highlighter-rouge"&gt;cufftComplex&lt;/code&gt; and &lt;code class="language-plaintext highlighter-rouge"&gt;cufftReal&lt;/code&gt;. Like I explained in the previous paragraph, this problem was quite similar in nature to the whole Python object to C object transformation and vice versa. If anything, this probably felt more explicit in nature since we could clearly see the actual C code written (as the RawModule’s string). The problem was that the structs are very specific to their definition, and it is simply not possible to pass anything to the RawModule and expect it to process it as a struct. Even though a numpy array of datatype complex64 might be storing the exact same data as an array of &lt;code class="language-plaintext highlighter-rouge"&gt;cufftComplex&lt;/code&gt;, the two cannnot be interconverted like vectors of integers and other primitive types can be. This again posed a challenge as it would mean a deviation from the original code. Finally, after reading a lot of stackoverflow and still not being satisfied with any of the answers, I let my mentors help me out with the code. The final solution that came out did a couple of things: first we got rid of the &lt;code class="language-plaintext highlighter-rouge"&gt;cufftComplex&lt;/code&gt; and &lt;code class="language-plaintext highlighter-rouge"&gt;cufftReal&lt;/code&gt; structs, and instead introduced the other, C datatype, serving the same purpose, a &lt;code class="language-plaintext highlighter-rouge"&gt;complex&amp;lt;float&amp;gt;&lt;/code&gt;. This amazing datatype did the exact same thing, except we could pass a numpy (or cupy) array of type complex64 and it would automatically read it as a &lt;code class="language-plaintext highlighter-rouge"&gt;complex&amp;lt;float&amp;gt;&lt;/code&gt; array! It quite literally solved the whole problem in an instant, and the only modifications we had to make were change how the real and imaginary parts of the complex numbers were being handled. While the struct definition required us to handle both separately, the new format made things even simpler by letting us perform calculations on both the real and imaginary parts simultaneously (basically how you’d expect to work with a complex number anyway!). With this, and again a few minor changes here and there to ensure the data transfer between Cython and CuPy wasn’t throwing errors, I was done! However, by now I had a Cython file with 1300+ lines with a &lt;em&gt;lot&lt;/em&gt; of room for bugs and unexpected errors and behavior.&lt;/p&gt;

&lt;p&gt;This brings us to the current time. The current objective for me is to get the file to work properly and produce the right about, so basically debugging. However, unlike smaller programs and files which are debugged with usually a single method in focus, I have to constantly let the whole chain of methods to execute even if I know that the bug is in some specific method, simply because its impossible to recreate the testing environment otherwise. For instance, I have been debugging the code since yesterday, and except one time where I got a segmentation fault, every time the program crashes, I am being forced to restart my computer just to start the debugging process again. Reason you ask? The program is working on a small subset of an already trimmed dataset, occupying around 3 GB of space. However, whenever I execute the program and try to run it, it is loading all that data first in the RAM (which slows the computer to a crawl almost instantly due to the limited 8GB RAM), and subsequently to the GPU (where it takes up 3/4 GB VRAM present). On force closing the program, while the RAM does free up after some time to a state where I can start using the computer again, the GPU does not!! I am yet to read into the nitty-gritty of this, but from what I understood, we need to explicitly clear the VRAM occupied by CuPy using methods given in the documentation. However, when the program does not work as expected (which is currently 100 percent of the times I have run it), the program simply crashes before executing the lines which free up the memory. The result? A GPU which is loaded up and unable to free its VRAM. Resetting seems to not work for some reason, and the only option I have found so far (admittedly I havent researched well enough but its only been 24 hours since I reached this stage) which does work is restarting my computer. This, as I am sure you can already feel, is a very frustrating way to debug things, but I am happy to say that I am still making progress, albeit a little slowly than I would have liked to.&lt;/p&gt;

&lt;p&gt;That pretty much sums up everything that I have been upto for the past 2 weeks. The progress is a little on the slower side, as I expected to have the demo working &lt;em&gt;and&lt;/em&gt; producing the correct output by now, but unfortunately the code still needs debugging. Hopefully this should be over soon, and we can then move to integrating it with RADIS and making changes that should allow the user to make use of our program. After that, we would be focussing on implementing other methods of calculating spectra, and possibly also methods which support non-equilibria conditions. Hopefully I should have a lot more to tell you guys 2 weeks from now! Till then, adios! And thanks for making it this far (if you actually did so :P) Cheers.&lt;/p&gt;</description><category>radis</category><guid>http://openastronomy.org/Universe_OA/posts/2020/06/20200629_2135_pkj-m/</guid><pubDate>Mon, 29 Jun 2020 20:35:56 GMT</pubDate></item><item><title>Google Summer of Code - Blog #1!</title><link>http://openastronomy.org/Universe_OA/posts/2020/06/20200613_2135_pkj-m/</link><dc:creator>pkj-m</dc:creator><description>&lt;p&gt;Hey there, welcome to the second blog of the series, and the first one to document the coding period. The Community bonding period which I described in my previous blog ended on 31st May and paved the way for the official coding period of the Google Summer of Code. These past two weeks were my first where I spent most of my time working on the actual code that will be a part of my project. My primary objective over these two weeks was to study the proof of work code that implements the spectral matrix algorithm to compute the spectra and execute it on a GPU. This was followed by a period of studying the different mechanisms with which RADIS calculates the spectras, and to understand the differences between each of them. This was important as implementing GPU compatible methods for all these distinct pipelines is my final objective and it is essential for me to understand the differences between these methods at the very onset of my project. Finally, the remaining time was spent on back and forth discussions with my mentors on various languages and libraries that could have been possible choices for undertaking this project. Once we had made our decision, I spent the time going through the library’s documentation, source code and tutorials to familiarize myself with these tools.&lt;/p&gt;

&lt;p&gt;The first major objective for these two weeks focussed on studying and executing the proof of work code. This was a single CUDA C file which demonstrated the idea of using a spectral matrix to compute a spectra while making use of a GPU could offer performance boosts of multiple orders over the naive methods. I initially planned on executing the code and running it on my personal computer, but the idea was quickly dismissed because of reasons I already discussed in my previous blog. As a result, I ended up using Google Colab for this experimentation which came with its own fair share of discomforts. The first, and most significant of which, was the lack of persistent storage on Colab and thus being forced to resort to Google Drive for saving our database instead. This was costly in terms of both, the time it took to store the data on the cloud and also on the overall performance of the code as the time taken to load the data to memory increased significantly compared to a single CPU-GPU system like my personal laptop. This however, was not detrimental to the fundamental objective as the benchmarking could be done for each part of the code separately, and thus it did not influence or affect the execution of the device code or its perfomance in any way. Another task which popped up when using Colab to run CUDA was to setup the system so it could run native CUDA C files along with the Python code as well. This fortunately was not very difficult to solve and a couple of google searches gave us the list of all the necessary packages we needed to compile and execute C files on Colab. Once that was set up, the only thing that was left for me to do was transfer the data from my laptop to Google Drive. This once again posed a problem that I had not anticipated. Uploading 8GB of data takes &lt;em&gt;much&lt;/em&gt; longer than downloading the same amount of data! As soon as that realization hit me, I decided to adopt another approach. I copied the code that I used to download the data from the FTP server to my local storage and ran it on Google Colab! This allowed me to once again redownload the entire data (which in the raw format was ~ 30GB) directly on my Drive instead. The process was much faster than I had anticipated and I soon had the raw data on my Drive. After running another couple of scripts to format and repartition the data into separate numpy arrays, I was ready to go. Execution of the code went smoothly except for a few hiccups surrounding the matplotlibcpp library that was being used to plot the output spectra. I wasn’t able to solve this problem immediately like the others and talked to my mentors about it. They advised me to not worry too much about it right now as it really wasn’t the critical part of the project. The major part, the kernel that was supposed to run on the GPU ran as expected and the results we obtained by timing the kernel performance were very positive! Now that I had successfully executed the code, what followed was a series of different runs of the same code, only this time with a different aim to test how far we could take this GPU compatible code. To give some numbers here, the original proof of work code that crunched the 8GB processed database computed a total of 240 million lines in less than a second! To be more specific, it took 120 ms on average to achieve that number. To put that into perspective, a naive implementation of the same code, that does not make use of the optimizations we did here, would take 10,000x longer to produce the same results! That in itself makes the naive approach an impractical solution to the problem. Compared to the current RADIS implementation, the performance gain was still significant with upto 50x gain in terms of time spent for computing the spectra. In order to see how far we could take this code, we also tried it with it a bunch of different ranges from the same dataset. While the original code was tested on a range that spanned from 1750 to 2400 cm-1 wavenumber, we took it as far as 1250-3050 cm-1. Surprisingly, the code scaled pretty well with the increase in the number of lines being computed, going from the original 120 ms taken to compute 240M lines to ~ 220 ms to compute 330M lines. Testing such a wide range and getting such positive results was sufficient proof for us to pack up the analysis part and move on to the actual implementation.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;

&lt;p&gt;In order to integrate the GPU compatible spectral matrix method with the RADIS code base, the first thing that needed to be worked on was the language itself. The proof of work had been written completely in CUDA C, while RADIS is pure-Python. In order to bridge this gap, we had multiple options. The first and most obvious was to simply rewrite the entire code using Python with the help of some CUDA library. This, however, meant a lot of work in re-implementing the multiple methods, and more importantly, did not allow us to reuse the code that already existed. Therefore, in order to maximize our efficiency and also get the best performance possible, we decided to use a new language, or more specifically – a language extension for Python, known as Cython. The idea behind Cython is to use Python with a static compiler, which allowed Python programs to be precompiled into binaries, which could then be imported to other Python programs and achieve performance on par with native C code, because that is the intermediary code Cython converts the Python code into! Thus, by extension, any code that was already written in C was directly compatible with Cython. The main task now was to get the C code we had with us to talk to Cython with as few modifications as possible. This infact, is something that is still ongoing and would be finished as a part of my first evaluation. The last few days of this period have mostly been spent on learning Cython and its nuances. While the idea of Cython is to provide a smooth experience for Python users to gain C-level performance, ironically I had the opposite experience with it. I found Cython quite confusing at the beginning, and while most resources and tutorials focussed on making Python code achieve C-level performance, I was genuinely surprised by the lack of documentation/tutorials explaining how to export C code that already exists to Python. The few examples that were mentioned on the website were very generic and did not help much in terms of my requirements, where I needed to use things like references of vectors, etc. However, with more research and googling, I was able to find a compromise solution that worked well and thus allowed me to execute the method in Cython with minimal modifications to the original code.&lt;/p&gt;

&lt;p&gt;Overall, I think its been a good two weeks with a lot of progress made on the knowledge front. Apart from the objectives mentioned above, I also went through the draft of the paper my mentors have been working on which goes into the mathematics of the method and explains how it works. While I wasn’t able to comprehend everything properly, it did give me a good high-level idea of what exactly we’re trying to accomplish with our kernels. With this, I think I’d like to conclude this blog. Over the next two weeks, the end of which will also mark the completion of my first evaluation, I’ll continue to work on Cython-izing our host code, and start looking into CuPy as an alternative to CUDA C for our project! More about that in the next blog! Thanks!&lt;/p&gt;</description><category>radis</category><guid>http://openastronomy.org/Universe_OA/posts/2020/06/20200613_2135_pkj-m/</guid><pubDate>Sat, 13 Jun 2020 20:35:56 GMT</pubDate></item><item><title>Google Summer of Code - Blog #0!</title><link>http://openastronomy.org/Universe_OA/posts/2020/05/20200530_1804_pkj-m/</link><dc:creator>pkj-m</dc:creator><description>&lt;p&gt;Hey there. Welcome to the first of what is going to be a series of blog posts chronicling my journey as I participate in the Google Summer of Code this year with RADIS (registered as a sub-org under OpenAstronomy). This particular blog post, as the title suggests, is meant to give a quick introduction to GSoC as well as my organization and the project.&lt;/p&gt;

&lt;h4 id="what-is-google-summer-of-code"&gt;What is Google Summer of Code?&lt;/h4&gt;
&lt;!-- TEASER_END --&gt;
&lt;p&gt;Borrowing straight from it’s landing page, Google Summer of Code is a global program focused on bringing more student developers into open source software development. Students work with an open source organization on a 3 month programming project during their break from school.
In other words, GSoC (as it is more commonly referred to) is a program sponsored by Google which aims to connect university students around the world with open source organizations in order to promote the open-source culture. The students get an opportunity to peek into the world of open source development, learn new skills and also get compensated for the work, quite generously. In turn, the organizations benefit from a few extra pairs of helping hands, using them for a wide array of issues, from refactoring code, to fixing existing bugs, and ofcourse, to add new features to the existing code base. It’s a great program and any college student interested in software development should definitely check it out. The website contains a lot more information &lt;a href="https://summerofcode.withgoogle.com/"&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Now that’s clear, let me talk a little about the specific organization that I will be working with.&lt;/p&gt;

&lt;h4 id="radis--openastronomy"&gt;RADIS ∈ OpenAstronomy&lt;/h4&gt;

&lt;p&gt;While the most commmon way for organizations to participate in the program and request slots for GSoC is to register directly, many organizations, for various reasons, often come together under an umbrella organization and register for GSoC as one single unit. This bundling of organizations can happen on various basis, but the most common reason is that these organizations often work towards the same goal, or operate in the same domain. In my case, this is true as well. I applied for and got selected for GSoC with the OpenAstronomy organization, which as the name suggests is an umbrella organization meant to act as a central hub for all the great number of ‘sub-organizations’ that operate within it. You can read more about OpenAstronomy and what it does &lt;a href="https://openastronomy.org/"&gt;here&lt;/a&gt;. One such sub-organization, with which I shall be working, happens to be RADIS.&lt;/p&gt;

&lt;p&gt;RADIS is a radiation software, a fast line-by-line code for synthesizing and fitting infrared absorption and emission spectra such as encountered in laboratory plasmas or exoplanet atmospheres.&lt;/p&gt;

&lt;p&gt;While RADIS was written with performance in mind, and performance it delivers, it is still limited by factors such as the speed offered by Python, and using a single CPU to carry out all its calculations. While the problem with a programming language can be solved (not so) easily by switching to other languages, such as C++, we’re still limited to using a single processing unit to carry out all the computations. This is the exact problem that my project tries to solve. The title of my project, “Accelerate Synthetic Spectra Calculations using CUDA”, is all about removing the restriction of a single CPU and instead allow RADIS to perform much faster by utilising the power of a GPU instead. I will not be going into the detail of the project here/yet, but the general idea is to switch certain parts of the pipeline in RADIS’ execution which slow it down to the GPU, which as people familiar with GPUs would know, is adept at executing a large volume of simple tasks.&lt;/p&gt;

&lt;p&gt;The technicalities of the project, including how exactly the problem can be shifted to the GPU, how its being implemented on the GPU, or its integration with the RADIS will be discussed in the future blog posts. For now, I will like to keep this blog limited to the things that have already occured, as a part of the ‘Community Bonding Period’:&lt;/p&gt;

&lt;h4 id="the-community-bonding-period"&gt;The Community Bonding Period&lt;/h4&gt;

&lt;p&gt;The Community Bonding Period is an almost 30-days long period meant to serve as a warm-up or a buffer before the actual coding period begins. It can be used for a wide variety of purposes, such as getting a better understanding of the codebase, figuring out the intricacies of your project et al. As such, the greater part of my community bonding period went into understanding the exact details of what I will be doing over the coming months and how I will be doing it. While the pre-selection period did include a fair amount of contributions being made by me towards the organization, it was mainly an attempt to understand the general architecture and codebase of RADIS more thoroughly, and did not involve anything specific to the project I had applied for. Once the selected projects were made public on 4th May 2020, that is when the community bonding period officially started and I started to focus exclusively on my project as well. The seed idea that eventually led to my project started when my mentors decided to play around with the code, and instead of using pure Python for the processing, decided to precompile some of the slower parts of the code into a DLL and imported it to Python instead. The results of this experiment were incredible, and paved the way for my mentor, Dirk van den Bekerom to write the first proof-of-work code demonstrating the use of GPUs to calculate the spectras that were previously being done entirely on the CPU. Benchmarking showed performance boosts of upto 10,000x compared to the naive implementation of spectra calculations on Python and upto 50x from the current implementation of RADIS.&lt;/p&gt;

&lt;p&gt;After discussing with my mentors, the project timeline was decided and the work was done accordingly. Keeping in mind my objectives for the coming month, as a part of the first evaluation, I decided to spend a lot of time on understanding the existing code base of RADIS &lt;em&gt;which focuses on the spectra calculations&lt;/em&gt;. Note that this is completely different from the code that I worked on earlier, which focussed on issues completely different from this, and mostly revolved around the post-processing of spectra instead of calculating it. This included a light reading of the original RADIS paper which talked about the general idea and logic behind RADIS. In addition to that, I also spent time on setting up the right environment for the development work that was to come.
Since the project is about GPUs and CUDA, I had to ensure that CUDA was properly installed and running on my system. While this might seem like a trivial task, it can easily get very messy when working on a linux distribution. Fortunately, I already had a working installation of CUDA on my system so I didn’t have to spend much time on it except for testing and tuning it. Another major issue that this project entailed was the handling of vast amounts of data.&lt;/p&gt;

&lt;p&gt;To keep it simple, in order to calculate the spectra, RADIS requires some data. This data includes information on various parameters such as positions, intensities, air- and self-broadened half-widths, et cetera for different molecules. For my project, for the time being, I was using the CDSD-4000 database, which is a high-temperature databank for CO2 molecule. The major issue this databank presented was the vast size of it. While the complete databank would have been incredibly huge (but fortunately not needed) the portion of the databank that we did focus on was not a small package either, occupying 30GB space unprocessed. Further processing of this data reduced it down to 8GB. While that might seem like a manageable size, the issue was that in order to compute the spectra efficiently and reduce the latency in loading the data, all of it had to be stored on the device RAM. This requirement was simply not possible for me to satisfy with just my personal computer which has a NVidia GTX 1650 with only 4GB of VRAM. Thus, I was left with two options. To either trim the database further and then work on it, or find another machine with specifications high enough to crunch the numbers without trimming it down. After discussing with my mentors and weighing the pros and cons, I decided to try out both.
We used Google Colab with its free GPU access to process the entire 8GB data in one go. The major problem we faced with this method was loading the data onto the colab server. Since even the processed files were 8GB, and Colab did not offer persistent storage, we would have to upload 8GB of data every time we wanted to test the code out, which ofcourse would not have been practical. This was solved by using Google Drive, which can be mounted in colab and work as a persistent storage setup. So far, I have thoroughly enjoyed the convenience and power offered by Colab, and that too for no charge, and hope it continues to perform so wonderfully. In addition, I also trimmed the original database down to smaller sizes and tried to process them on my personal machine, which it did without any hassles.&lt;/p&gt;

&lt;p&gt;Another interesting question that we faced was the tools to use. While it might seem like a no-brainer to use C with CUDA, it unfortunately was not an option as RADIS was written in Python. Therefore, we had to spend a fair amount of time trying to figure out additions to Python in the form of libraries which allow CUDA access. A few of the many different options that are available for such purposes include using Cython, PyCUDA, Cupy, Numba, PyOpenCL and many more. The decision to pick one over the other is a very subjective one, and the answer mostly depends on the kind of application you’re trying to produce. For our particular project, the only requirement was to have access to constant memory on the device which can be achieved using Cython or PyCUDA. While I personally enjoyed PyCUDA due to its extensive documentation and support from NVidia, my mentor seems to prefer Cython so the final decision is still not here!&lt;/p&gt;

&lt;p&gt;Apart from all this, I also spent a good amount of time studying the proof-of-work code that already exists. That included the differences from pure CPU code, the division of work between host and the device, and way the the actual calculations are being done in order to compute the spectra. Finally, I also spent a fair amount of time on revising my CUDA concepts in order to ensure there were no knowledge gaps.&lt;/p&gt;

&lt;p&gt;That pretty much sums up my community bonding period! Over the coming 4 weeks, my objectives include reproducing the proof of work, and figure out the implementation details with my mentors. That will be followed by implementing one of the broadening steps in Python and integrating it with the RADIS.&lt;/p&gt;

&lt;p&gt;I am quite excited about the upcoming months and my journey with RADIS. I believe it will be a great learning experience and I would like to thank Google, OpenAstronomy, RADIS, but most importantly, my incredibly helpful and fun mentors Erwan Pannier, Dirk van den Bekerom and Minesi N for giving me this wonderful opportunity!&lt;/p&gt;</description><category>radis</category><guid>http://openastronomy.org/Universe_OA/posts/2020/05/20200530_1804_pkj-m/</guid><pubDate>Sat, 30 May 2020 17:04:56 GMT</pubDate></item><item><title>Google Summer of Code - Blog #0!</title><link>http://openastronomy.org/Universe_OA/posts/2020/05/20200514_1804_pkj-m/</link><dc:creator>pkj-m</dc:creator><description>&lt;p&gt;Hey there. Welcome to my first blog of an upcoming series of blogs where I will be trying to chronicle my journey this year as an open source contributor to RADIS under the Google Summer of Code program!&lt;/p&gt;

&lt;p&gt;Stay tuned!&lt;/p&gt;
&lt;!-- TEASER_END --&gt;

&lt;p&gt;-p&lt;/p&gt;</description><category>radis</category><guid>http://openastronomy.org/Universe_OA/posts/2020/05/20200514_1804_pkj-m/</guid><pubDate>Thu, 14 May 2020 17:04:56 GMT</pubDate></item></channel></rss>