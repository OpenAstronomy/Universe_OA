<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Universe OpenAstronomy (Posts by Biswarup Banerjee)</title><link>http://openastronomy.org/Universe_OA/</link><description></description><atom:link href="http://openastronomy.org/Universe_OA/authors/biswarup-banerjee.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><lastBuildDate>Wed, 18 Dec 2024 01:16:27 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Connecting Spark Logs with Jupyter UI</title><link>http://openastronomy.org/Universe_OA/posts/2020/07/20200727_1341_techguybiswa/</link><dc:creator>Biswarup Banerjee</dc:creator><description>&lt;p&gt;I have successfully been able to show the kernel logs in realtime into the Jupyter front end.&lt;br&gt;
So basically I configured the Jupyter kernel to dump the logs in real-time in a log file.&lt;br&gt;
Then I created a new function that runs in a separate thread and pulls the content of the log file every 2 seconds.&lt;br&gt;
&lt;!-- TEASER_END --&gt;
Then the fetched data is sent to the front end via sockets every two seconds ONLY when the user opens the log.&lt;br&gt;
So when the user is not in the logs page the socket communication and the reading of the log file do not happen.&lt;/p&gt;
&lt;blockquote&gt;def fetch_logs(comm):&lt;/blockquote&gt;&lt;blockquote&gt;f = open(“log.file”, “r”)&lt;/blockquote&gt;&lt;blockquote&gt;logs = f.read()&lt;/blockquote&gt;&lt;blockquote&gt;comm.send({‘status’ : ‘log_fetched_success’ , ‘log’ : logs})&lt;/blockquote&gt;&lt;blockquote&gt;if (ipython.ev(‘shouldFetchLog’)):&lt;/blockquote&gt;&lt;blockquote&gt;threading.Timer(2.0,fetch_logs, [comm]).start()&lt;/blockquote&gt;&lt;img src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=3a522a2b89e4" width="1" height="1"&gt;</description><category>astronomy-commons</category><guid>http://openastronomy.org/Universe_OA/posts/2020/07/20200727_1341_techguybiswa/</guid><pubDate>Mon, 27 Jul 2020 12:41:49 GMT</pubDate></item><item><title>1.5 months later</title><link>http://openastronomy.org/Universe_OA/posts/2020/07/20200713_1527_techguybiswa/</link><dc:creator>Biswarup Banerjee</dc:creator><description>&lt;p&gt;Time flies. &lt;br&gt;
It feels like yesterday that I joined DiRAC virtually and now that I look back, already a month and a half!&lt;/p&gt;
&lt;p&gt;It has been a really amazing journey so far and I have learned a lot, wrote a lot of code and have worked with some really nice people.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;p&gt;The most challenging aspect was connecting everything and putting everything together.&lt;/p&gt;
&lt;p&gt;I was working on an Ipython kernel extension, a Jupyter Notebook Front end extension, and on a python backend extension.&lt;/p&gt;
&lt;p&gt;I had to integrate REST APIs to connect the Front end with the backend and create socket communications to connect the front end with the ipython kernel.&lt;/p&gt;
&lt;p&gt;It was fun and challenging.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The features I added this week are:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;Saving the state of the extension across multiple devices&lt;/li&gt;&lt;li&gt;Customizing the cluster config from the front end&lt;/li&gt;&lt;/ol&gt;&lt;img src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=7bfd02021440" width="1" height="1"&gt;</description><category>astronomy-commons</category><guid>http://openastronomy.org/Universe_OA/posts/2020/07/20200713_1527_techguybiswa/</guid><pubDate>Mon, 13 Jul 2020 14:27:50 GMT</pubDate></item><item><title>Launching Version 1 of Start Spark</title><link>http://openastronomy.org/Universe_OA/posts/2020/06/20200629_2034_techguybiswa/</link><dc:creator>Biswarup Banerjee</dc:creator><description>&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*GKZekrHbmzNBggdsyVxSSA.jpeg"&gt;&lt;figcaption&gt;Even my workstation is excited for the product demo!&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;So after 4 weeks of planning and coding and debugging, the day came when I had to launch version 1.0 of the product!&lt;/p&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*JGcxp4eCl8d7t0omgPAFIQ.png"&gt;&lt;figcaption&gt;My extension “Start Spark” deployed at the prod servers&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;The extension I built is now deployed in the DiRAC Jupyter Hub and is currently getting used by the astronomy community at DiRAC!&lt;/p&gt;
&lt;p&gt;What you can do with my extension:&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;ol&gt;&lt;li&gt;Create a PySpark cluster on the click of a single button. Creating a PySpark cluster would have otherwise taken writing multiple lines of cumbersome codes.&lt;/li&gt;&lt;li&gt;Get the link where you can access the PySpark web UI and see all the executors, jobs, and the environment.&lt;/li&gt;&lt;li&gt;The “spark” variable is automatically injected into the kernel and hence users can use it as they like.&lt;/li&gt;&lt;/ol&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*qUI3KU07owQgFF6x35_V4Q.png"&gt;&lt;figcaption&gt;Get access to the PySpark Web UI&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*shTWfgSYlHyTD-KkB7w2mw.png"&gt;&lt;figcaption&gt;“spark” variable is injected in the kernel&lt;/figcaption&gt;&lt;/figure&gt;&lt;h4&gt;How does it work?&lt;/h4&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/976/1*sV-BVWeI7hPzr1ZyYFGmKA.png"&gt;&lt;figcaption&gt;Workflow&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Step 1: The extension gets loaded.&lt;br&gt;
Step 2: While it loads it automatically calls an API/serverextension handler /all-config and that API gives all the list of the available configs.&lt;br&gt;
Step 3: We can see that list of all available configs in the dropdown.&lt;br&gt;
Step 4: We can select any config that we want and click on “Start Spark” Button&lt;br&gt;
Step 5 : When we click Start Spark Button, the front end detects which config we have selected and then tells the serverextension about the selected config via REST API.&lt;br&gt;
Step 6: The serverextension fetches all the config details of the config that is selected in the frontend from the config dir located at home dir.&lt;br&gt;
Step 7: Then once it has the required config fetched from the config dir it converts it into a Jinja Template and sends the jinja template to the front end via API&lt;br&gt;
Step 8: Once the front end receives the Jinja template of the required config it sends the Jinja Template to the Kernel Extension via Sockets&lt;br&gt;
Step 9: The kernel extension executes the jinja template to start the spark cluster that it receives from the Jupyter front end.&lt;/p&gt;
&lt;blockquote&gt;Select Config -&amp;gt; Click the Start Spark Button -&amp;gt; Config Data fetched in backend -&amp;gt; Config data converted to Jinja Template in Backend -&amp;gt; Jinja Template Sent from backend to front end -&amp;gt; Jinja sent from front end to Kernel → Jinja template gets executed in Kernel to start the cluster!&lt;/blockquote&gt;&lt;p&gt;&lt;strong&gt;Video Reference Link&lt;/strong&gt;: &lt;a href="https://slack-redir.net/link?url=https%3A%2F%2Fwww.loom.com%2Fshare%2Fdc18b670e08a47c6a96db3176f3be9ef"&gt;https://www.loom.com/share/dc18b670e08a47c6a96db3176f3be9ef&lt;/a&gt; (PS: Watch it in 1.5x speed)&lt;/p&gt;
&lt;p&gt;I am super excited to see how the astronomy community feels about it and gives their feedback.&lt;/p&gt;
&lt;img src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=b16c4e9516fb" width="1" height="1"&gt;</description><category>astronomy-commons</category><guid>http://openastronomy.org/Universe_OA/posts/2020/06/20200629_2034_techguybiswa/</guid><pubDate>Mon, 29 Jun 2020 19:34:53 GMT</pubDate></item><item><title>2 Weeks at DiRAC</title><link>http://openastronomy.org/Universe_OA/posts/2020/06/20200620_1723_techguybiswa/</link><dc:creator>Biswarup Banerjee</dc:creator><description>&lt;p&gt;&lt;strong&gt;BiWeekly GSoC Updates Blog Post&lt;/strong&gt;&lt;/p&gt;
&lt;figure&gt;&lt;img alt="Data Intensive Research in Astronjomy and Astrophysics" src="https://cdn-images-1.medium.com/max/1024/1*Ek9a1DbEALyFlh8ueU56wQ.jpeg"&gt;&lt;figcaption&gt;Data-Intensive Research in Astronomy and Cosmology&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;In all my previous internships/contract-work I have worked with only the web stack and that too on the web front end specifically.&lt;br&gt;
All through the past years, I have been part of creating large scale consumer-facing web apps mostly with Javascript and related frameworks like React, Vue, and Angular.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;p&gt;But when I started working with DiRAC’s Data Engineering team, I had to work on a totally different tech stack!&lt;/p&gt;
&lt;p&gt;The Data Engineering team worked on Jupyter Lab and Jupyter Notebooks. They also worked mostly with Python/Go-related tech stack and frameworks and on very impressive DevOps stuff on AWS and also on their own EPYC servers.&lt;/p&gt;
&lt;p&gt;Although I had experience in Python mostly from solving LeetCode questions, but not a development experience with Python Frameworks. And I never heard of the Jupyter ecosystem before working at DiRAC. And the biggest DevOps stuff I have had ever done was hosting my projects on simple hosting services like Netlify.&lt;/p&gt;
&lt;blockquote&gt;So all these terms like Jupyter Notebook, Jupyter Lab, EPYC, Pyspark, Tornado, were totally alien to me.&lt;/blockquote&gt;&lt;p&gt;It was a new learning curve for me but definitely very interesting, intriguing, and challenging at the same time.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Also and most importantly, my mentors were super supportive and they communicated everything to the minutest details and helped me with links of all the necessary documentation and explained the workflows over video calls.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Well, apart from tech stack, I came to know a lot of people from DiRAC as we interacted over the weekly data engineering meetings. &lt;br&gt;
I had interactions with Colin, Dino, Andy, Chris, and Brigitta who are working on the Data Engineering team.&lt;/p&gt;
&lt;p&gt;Regarding my GSoC project, we are trying to build an MVP and launch a minimal version by the end of next week.&lt;/p&gt;
&lt;img src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=9525ec15bc20" width="1" height="1"&gt;</description><category>astronomy-commons</category><guid>http://openastronomy.org/Universe_OA/posts/2020/06/20200620_1723_techguybiswa/</guid><pubDate>Sat, 20 Jun 2020 16:23:18 GMT</pubDate></item><item><title>Tryst with Astronomy and Space Science</title><link>http://openastronomy.org/Universe_OA/posts/2020/05/20200521_0452_techguybiswa/</link><dc:creator>Biswarup Banerjee</dc:creator><description>&lt;h4&gt;Tryst with Astronomy and Computer science&lt;/h4&gt;&lt;p&gt;When I was very young, my dad used to tell me stories of how people can float in space because of zero gravity, how brave Indian astronauts like Kalpana Chawla gave their life for the pursuit of space science and that the stars we see in the night sky are several light-years away!&lt;/p&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/550/1*eVw2qOKIvYB8HmYgW1-Q2A.png"&gt;&lt;figcaption&gt;My dad telling me stories&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Many a time I would lay down on our open terrace and stare at the never-ending sky filled with millions of stars and just ruminate on the fact that we are living in such a vast universe!&lt;/p&gt;
&lt;p&gt;Then came high school and while randomly browsing the internet I came across a few articles written by Al Globus who happened to be one of the Board of Directors of The National Space Society.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;p&gt;In the articles, he talked about how humans can live in outer space and how humans will someday become a multi-planet and multi-orbital species.&lt;/p&gt;
&lt;p&gt;I instantly was captivated by the idea of living in space and I spent that year of high school designing a space settlement that could sustain the life of 10,000 residents. I even wrote C++ programs that could help calculate the amount of oxygen, food, water, the surface area, and the radius of the torus needed to sustain a given amount of population.&lt;br&gt;
Eventually, I sent my design to the NASA AMES SPACE SETTLEMENT CONTEST 2015, and our team got an honorable mention!&lt;/p&gt;
&lt;p&gt;The next year, I got an amazing opportunity to work on a collaborative project funded by the US Department of State!&lt;br&gt;
In that project, our team from &lt;a href="https://ncsm.gov.in/"&gt;NCSM India&lt;/a&gt;, and another team from &lt;a href="https://chabotspace.org/"&gt;Chabot Space Science Center, California&lt;/a&gt; worked on designing “space-spin off” technologies that could be used to control pollution levels on earth.&lt;br&gt;
It was really fun and a great learning experience for me and it taught me a lot about collaboration, teamwork, and about how much space science affects our day to day life! &lt;br&gt;
Our project was even featured in many media channels!&lt;/p&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/871/1*15BFL6H9M7WQrWudL7TXtA.png"&gt;&lt;figcaption&gt;India + US team meeting near UC Berkeley.&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure&gt;&lt;img alt="I am with the green Shirt" src="https://cdn-images-1.medium.com/max/543/1*FQaKhO0brsxCm66MNXiVHg.png"&gt;&lt;figcaption&gt;Getting featured in Times Of India&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;After this, I went to college! My college was nothing less than a roller coaster ride!&lt;/p&gt;
&lt;p&gt;So, I dedicated most of my time learning to code, doing internships, traveling to as many hackathons and tech events as possible, and having a good social life!&lt;br&gt;
I worked for some really cool tech startups like&lt;a href="https://pratilipi.com/"&gt; Pratilipi.com&lt;/a&gt; (one of India’s largest vernacular self-publishing platforms), &lt;a href="https://www.upgrad.com/"&gt;upGrad.com&lt;/a&gt; (Linkedin’s top 20 startups 2019–2020) and even went to &lt;a href="https://imaginecup.microsoft.com/en-us/Events?id=0"&gt;Microsoft Imagine Cup’s National Finals&lt;/a&gt;!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;And one of the coolest things that happened in my final year of engineering is that I got into Google Summer Of Code 2020 with &lt;/em&gt;&lt;/strong&gt;&lt;a href="https://openastronomy.org/"&gt;&lt;strong&gt;&lt;em&gt;OpenAstronomy.org&lt;/em&gt;&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;&lt;em&gt;!&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Inside the OpenAstronomy Organization, I would be working with the &lt;a href="https://dirac.astro.washington.edu/"&gt;DIRAC or &lt;em&gt;Data Intensive Research in Astrophysics and Cosmology&lt;/em&gt;&lt;/a&gt; at the University of Washington.&lt;/p&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*WAn4V8DHfxMOJSQBLZF-Dg.png"&gt;&lt;figcaption&gt;My Mentors from DIRAC: TOP LEFT: Steven TOP RIGHT: Me (Biswarup) BOTTOM: Professor Mario&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;I had multiple team meetings over zoom and I am totally fascinated by the people behind &lt;a href="https://dirac.astro.washington.edu/"&gt;DIRAC&lt;/a&gt;. They are a very experienced and passionate team of astronomers, engineers, and researchers and I feel really lucky to be part of such an amazing group!&lt;/p&gt;
&lt;p&gt;The projects that they work on include building tools and software for analyzing very large data sets (in terabytes and petabytes) coming from &lt;a href="https://www.lsst.org/"&gt;The Large Synoptic Survey Telescope&lt;/a&gt; or the LSST and from the &lt;a href="https://www.ztf.caltech.edu/"&gt;Zwicky Transient Facility (ZTF)&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The project that I will be working on is a very interesting one and it revolves around building a user interface/dashboard that would allow astronomers/space scientists to easily create and manage Apache Pyspark from their Jupyter Notebooks. With the dashboard, the astronomers would no longer have to write multiple lines of code to launch and manage a pyspark cluster, and instead, they can achieve that by a very user-friendly drag and drop interface!&lt;/p&gt;
&lt;p&gt;In the next 3 months, I will be working with my GSoC mentors &lt;a href="https://depts.washington.edu/astron/profile/stetzler-steven/"&gt;Steven&lt;/a&gt; and &lt;a href="https://dirac.astro.washington.edu/team_member/mario-juric/"&gt;Professor Mario Juric&lt;/a&gt; and the other teammates at DIRAC’s Data Engineering Group, and I am very much excited for the same!&lt;/p&gt;
&lt;p&gt;Linkedin: &lt;a href="https://www.linkedin.com/in/techguybiswa/"&gt;https://www.linkedin.com/in/techguybiswa/&lt;/a&gt;&lt;br&gt;
Mail-Id: bis.banerjee.bb@gamil.com&lt;/p&gt;
&lt;p&gt;Thanks &lt;a href="https://medium.com/u/ffd8efb5df45"&gt;gishtah&lt;/a&gt; for helping me to edit my post!&lt;/p&gt;
&lt;img src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=b8df974cb159" width="1" height="1"&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://blog.usejournal.com/tryst-with-astronomy-and-space-science-b8df974cb159"&gt;Tryst with Astronomy and Space Science&lt;/a&gt; was originally published in &lt;a href="https://blog.usejournal.com"&gt;Noteworthy - The Journal Blog&lt;/a&gt; on Medium, where people are continuing the conversation by highlighting and responding to this story.&lt;/p&gt;</description><category>astronomy-commons</category><guid>http://openastronomy.org/Universe_OA/posts/2020/05/20200521_0452_techguybiswa/</guid><pubDate>Thu, 21 May 2020 03:52:58 GMT</pubDate></item></channel></rss>