<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Universe OpenAstronomy (Posts about gsoc2020)</title><link>http://openastronomy.org/Universe_OA/</link><description></description><atom:link href="http://openastronomy.org/Universe_OA/categories/cat_gsoc2020.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><lastBuildDate>Tue, 30 Jun 2020 01:33:11 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Launching Version 1 of Start Spark</title><link>http://openastronomy.org/Universe_OA/posts/2020/06/20200629_2034_techguybiswa/</link><dc:creator>Biswarup Banerjee</dc:creator><description>&lt;div&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*GKZekrHbmzNBggdsyVxSSA.jpeg"&gt;&lt;figcaption&gt;Even my workstation is excited for the product¬†demo!&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;So after 4 weeks of planning and coding and debugging, the day came when I had to launch version 1.0 of the¬†product!&lt;/p&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*JGcxp4eCl8d7t0omgPAFIQ.png"&gt;&lt;figcaption&gt;My extension ‚ÄúStart Spark‚Äù deployed at the prod¬†servers&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;The extension I built is now deployed in the DiRAC Jupyter Hub and is currently getting used by the astronomy community at¬†DiRAC!&lt;/p&gt;
&lt;p&gt;What you can do with my extension:&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;ol&gt;&lt;li&gt;Create a PySpark cluster on the click of a single button. Creating a PySpark cluster would have otherwise taken writing multiple lines of cumbersome codes.&lt;/li&gt;&lt;li&gt;Get the link where you can access the PySpark web UI and see all the executors, jobs, and the environment.&lt;/li&gt;&lt;li&gt;The ‚Äúspark‚Äù variable is automatically injected into the kernel and hence users can use it as they¬†like.&lt;/li&gt;&lt;/ol&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*qUI3KU07owQgFF6x35_V4Q.png"&gt;&lt;figcaption&gt;Get access to the PySpark Web¬†UI&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*shTWfgSYlHyTD-KkB7w2mw.png"&gt;&lt;figcaption&gt;‚Äúspark‚Äù variable is injected in the¬†kernel&lt;/figcaption&gt;&lt;/figure&gt;&lt;h4&gt;How does it¬†work?&lt;/h4&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/976/1*sV-BVWeI7hPzr1ZyYFGmKA.png"&gt;&lt;figcaption&gt;Workflow&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Step 1: The extension gets loaded.&lt;br&gt;
Step 2: While it loads it automatically calls an API/serverextension handler /all-config and that API gives all the list of the available configs.&lt;br&gt;
Step 3: We can see that list of all available configs in the dropdown.&lt;br&gt;
Step 4: We can select any config that we want and click on ‚ÄúStart Spark‚Äù Button&lt;br&gt;
Step 5¬†: When we click Start Spark Button, the front end detects which config we have selected and then tells the serverextension about the selected config via REST API.&lt;br&gt;
Step 6: The serverextension fetches all the config details of the config that is selected in the frontend from the config dir located at home dir.&lt;br&gt;
Step 7: Then once it has the required config fetched from the config dir it converts it into a Jinja Template and sends the jinja template to the front end via API&lt;br&gt;
Step 8: Once the front end receives the Jinja template of the required config it sends the Jinja Template to the Kernel Extension via Sockets&lt;br&gt;
Step 9: The kernel extension executes the jinja template to start the spark cluster that it receives from the Jupyter front¬†end.&lt;/p&gt;
&lt;blockquote&gt;Select Config -&amp;gt; Click the Start Spark Button -&amp;gt; Config Data fetched in backend -&amp;gt; Config data converted to Jinja Template in Backend -&amp;gt; Jinja Template Sent from backend to front end -&amp;gt; Jinja sent from front end to Kernel ‚Üí Jinja template gets executed in Kernel to start the¬†cluster!&lt;/blockquote&gt;&lt;p&gt;&lt;strong&gt;Video Reference Link&lt;/strong&gt;: &lt;a href="https://slack-redir.net/link?url=https%3A%2F%2Fwww.loom.com%2Fshare%2Fdc18b670e08a47c6a96db3176f3be9ef"&gt;https://www.loom.com/share/dc18b670e08a47c6a96db3176f3be9ef&lt;/a&gt; (PS: Watch it in 1.5x¬†speed)&lt;/p&gt;
&lt;p&gt;I am super excited to see how the astronomy community feels about it and gives their feedback.&lt;/p&gt;
&lt;img src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=b16c4e9516fb" width="1" height="1"&gt;&lt;/div&gt;</description><category>astronomy-commons</category><guid>http://openastronomy.org/Universe_OA/posts/2020/06/20200629_2034_techguybiswa/</guid><pubDate>Mon, 29 Jun 2020 19:34:53 GMT</pubDate></item><item><title>GSoC 2020: glue-solar project 1.2</title><link>http://openastronomy.org/Universe_OA/posts/2020/06/20200629_1911_kakirastern/</link><dc:creator>Kris Stern</dc:creator><description>&lt;div&gt;&lt;p&gt;It has been a month since GSoC‚Äôs coding period started early in June 2020. Much has happened since then in the glue-solar project, and to sum it up I have been pretty much spending all my GSoC time working on a WCSAxes-enabled version the 1D Profile viewer for extracting 1D spectrum from data cubes using the pixel extracted in a 2D Image viewer. To be honest it has been very effort-intensive, though not necessarily time-intensive as I have previously feared. But the journey has been fun given my very supportive and friendly project mentors. To the layman and non-specialist what I have related regarding the project details probably sounds esoteric, which it is. With this realization I will split this and remaining GSoC blog posts into two halves: one pertaining to my personal struggles, and the other pertaining to the technical aspect of the work carried out thus far, in that order, so that that latter part can be conveniently skipped over (but I do encourage you to do read both sections in tandem so get a better understanding of the project¬†:-p) Anyway, let me¬†begin‚Ä¶&lt;/p&gt;
&lt;h4&gt;Part 1: Personal struggles&lt;/h4&gt;&lt;p&gt;One personal ‚Äúsecret‚Äù I wish to reveal is that this is my last year as a PhD Candidate in Astrophysics at the University of Hong Kong (HKU). Not only that, since my Postgraduate Scholarship officially ran out in October 2019 and no other funding options are available, I have been holding down a job as a front-end developer for some parts of the weekdays to support my PhD studies. So far I have been trying to manage my time wisely and balancing my various duties and obligations as best as possible, but it has been a genuine struggle, especially in me trying to find enough time to sleep. To make matters worse I have a tendency to drift towards writing code than writing my thesis, though I am making progress in both. So I did hesitated to apply for GSoC for a 2nd time this year and was originally against the idea. But when I saw the project ideas available I changed my mind. Glue-solar is actually like a godsend for me; the project enabled me to not only further develop my self-discipline as a person, it also allowed me to learn from experts in the field working on open-source data visualization, and to grow from the experience. I thoroughly enjoyed interacted with my mentors, who have been very patient and helpful in offering me guidance (as well as friendship) throughout. If I have any advice I am allowed to offer anyone wanting to try out open-source software development through GSoC, and if GSoC does continue in the near future, I would recommend them to try out any of the OpenAstronomy projects. This is because OpenAstronomy is one (relatively) small but vibrant community of dedicated programmers, many of which scientists, that is welcoming to newcomers coming from a diverse background. And also, simply put, ASTRONOMY IS FUN! This is especially true for SunPy. I remember I started to contribute to open-source software as a relative novice with some bookish knowledge but not a lot of real-world experience back in around January 2019. My first contributions were to SunPy and Astropy. I remember I have read an article about how to get into GSoC in 2018 to learn about the program, though was not all that keen in getting into it at first. My first motivation to contribute was to give back to the community, because I had been using Python-based astronomy packages like Astropy for my PhD research. But at the urge of a mentor active in the Astropy community, I did apply. The GSoC project I worked on last year in 2019 was &lt;a href="https://summerofcode.withgoogle.com/archive/2019/projects/6094580905148416/"&gt;IRISpy&lt;/a&gt;, and my mentors were &lt;strong&gt;Dan Ryan&lt;/strong&gt; and &lt;strong&gt;Laura Hayes&lt;/strong&gt;. They were amazing as mentors, and were instrumental in my being able to complete the project successfully in the end of the program. I still miss my time spent with them on that project. IRISpy has officially changed its name to sunraster, which I was fortunate enough to help launch earlier this year in 2020. Basically when I was working on it as a GSoC project it was to provide additional functionalities for the analysis of observations from NASA‚Äôs Interface Region Imaging Spectrograph (IRIS) satellite which looks at UV emission from the solar chromosphere in particular. Now that scope has been extended to not just IRIS data, but data collected with similar instruments. This year I am using a lot of the code I have written for the IRISpy project for the current glue-solar project, which is kind of cool. As an icing to the cake, I get to work on data cubes for glue-solar, which is one of my favorite things in this world, a passion I have gained through my PhD research into integral field spectroscopy (IFS). For the present GSoC work I even get to work on &lt;strong&gt;4D data cubes (ones with an extra &lt;em&gt;time&lt;/em&gt; dimension)&lt;/strong&gt;, which has one more dimension than the IFS cubes I am so familiar with! So far it has been another incredible GSoC experience for me. All in all I have a feeling it will be a good one, and also a fruitful¬†one.&lt;/p&gt;
&lt;h4&gt;Part 2: Technical aspect of progress made in glue-solar&lt;/h4&gt;&lt;p&gt;So we (me and my mentors) have ventured away from focusing on glue-solar and have entered the glue ‚Äúproper‚Äù territory as we put more time and effort towards modifying the 1D Profile viewer. By this I mean we have begun work on glue instead of glue-solar as was the case as described in &lt;a href="https://medium.com/@krisastern/gsoc-2020-glue-solar-project-1-1-c2151e535e0c"&gt;my previous article&lt;/a&gt; where we have built a ‚ÄúSunPy Map‚Äù viewer. So I am well on my way to complete the task ‚Äúmodifying the existing glue 1D Profile viewer to provide sliders for extra dimensions (currently collapses)‚Äù soon, which is a significant part of the glue-solar project. Personally, I am really looking forward to working on the ‚Äúadding support for pre-computed statistics in datasets / viewers‚Äù task, which I will surely make time to complete before end of¬†August.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;p&gt;Let me demonstrate how far we have come with the modification of the 1D Profile viewer. So ordinarily it is hard to get 4D data cubes with a time dimension. This can be fixed by stacking sequential (IRIS) raster scans/cubes. After firing up glue from the terminal by the magic command ‚Äúglue‚Äù, and importing some if not all raster scans from the same observation using the IRIS OBS directory importer, and choosing to ‚ÄúStack the sequential raster scans‚Äù¬†, we see some data points appearing in the Data field of the GUI. This is illustrated by the sequence of images to¬†follow:&lt;/p&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*5te3r5u7q5pxeWhiBv4x9Q.png"&gt;&lt;figcaption&gt;&lt;strong&gt;Figure 1.&lt;/strong&gt; Loading an multi-scan IRIS Observation and choosing to stack the sequential raster scans /¬†cubes.&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*DvJ0gwjAKMjdGefNeggEpA.png"&gt;&lt;figcaption&gt;&lt;strong&gt;Figure 2.&lt;/strong&gt; Stacked datasets which are essentially 4D data cubes appear in the Data field of the glue-solar GUI.&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*c1fcKBkCGbcibrc2nfU93w.png"&gt;&lt;figcaption&gt;&lt;strong&gt;Figure 3.&lt;/strong&gt; As per usual, choosing the 2D Viewer option will enable us to inspect the different sides of the N-dimensional or ND data¬†cube.&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*A_dQDmastlGwmif17b7J2Q.png"&gt;&lt;figcaption&gt;&lt;strong&gt;Figure 4.&lt;/strong&gt; Choosing the right (N-1) slices for the slicing to obtain the 1D profile (which I have learned in a hard way is not always the same as a 1D spectrum coding-wise) using some pre-defined logic that warrants some explanation, though should be intuitive to¬†some.&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*Qq70FXHsyObzBniXG35BOQ.png"&gt;&lt;figcaption&gt;&lt;strong&gt;Figure 5.&lt;/strong&gt; Using the 1D Profile tool, as opposed to the red 1D spectrum button in the 2D Image viewer, to generate the desired profile, which may or may not be a 1D spectrum.&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*FuXVHmy-MOFS-ELa6gFSUw.png"&gt;&lt;figcaption&gt;&lt;strong&gt;Figure 6.&lt;/strong&gt; Plotting of the uncollapsed version of the 1D profile by choosing the newly added ‚ÄúSlice‚Äù function which does nothing statistical to the data like the other functions such as ‚ÄúMaximum‚Äù, ‚ÄúMedian‚Äù, and ‚ÄúSum‚Äù that can be chosen as alternatives. (The default is ‚ÄúMaximum‚Äù).&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;As we can see in Figure 6, all 4 dimensions are represented in the 1D Profile viewer either as the x-axis or as a slider quantity. In this example, the x-axis is indeed wavelength (which yields a 1D spectrum by definition), the other dimensions are time, longitude (HPLN), and latitude (HPLT). Even though for now the sliders are still not yet functional and will need some tender loving care to make them work in tandem with the reference data as inherited or passed from the 2D Image viewer, which may take a few more days to complete, I believe this is truly a milestone in this GSoC project. If we can control the sliders to change the coordinate values, that would be a very useful tool in data exploration. I will spare the perhaps rather dry details regarding the reasoning through the whole thinking process that leads to this check point. However, I would like to explain the logic used in the slicing. What I have done is to introduced a SlicedData class, much like the existing IndexedData class that is used for pixel extraction with a tool my mentor &lt;strong&gt;Stuart Mumford&lt;/strong&gt; originally wrote for glue-solar (currently in a draft PR to be upstreamed to glue). First to pick a spatial coordinate, we choose in the 2D Image viewer the spatial axes for the image axes, selecting a point in the image shown on screen with the pixel selection tool, and then tweak the slider we would like its corresponding axis to be used as the x-axis in the 1D Profile viewer. Then we drag the same dataset to the viewing area and view using the 1D Profile viewer, in order to generate a profile for the slicing we have chosen. So this has been the work completed thus far. What is yet to be completed is to enable the manipulating of the 4D or higher dimensional data cube using the sliders for the same x-axis. So in the end regardless of the starting point, we could potentially use the 1D profile viewer to inspect the 4D or ND data cube in ways previously impossible before, at least to¬†me.&lt;/p&gt;
&lt;p&gt;Again, I would like to thank my mentors for their guidance and support which enabled the progress I have made to happen. Much work will need to be done in order for the PRs to be polished up and merged later on in the summer. I really enjoy my glue-solar work for GSoC this summer. I hope you enjoyed reading this article as much as I had fun writing it¬†too!&lt;/p&gt;
&lt;img src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=65ef40ba2b71" width="1" height="1"&gt;&lt;/div&gt;</description><category>SunPy</category><guid>http://openastronomy.org/Universe_OA/posts/2020/06/20200629_1911_kakirastern/</guid><pubDate>Mon, 29 Jun 2020 18:11:30 GMT</pubDate></item><item><title>GSoC 2020: Generalization of Clients</title><link>http://openastronomy.org/Universe_OA/posts/2020/06/20200629_1813_abhijeetmanhas/</link><dc:creator>Abhijeet Manhas</dc:creator><description>&lt;div&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/800/0*EsjuLxEt1BrtrdCG"&gt;&lt;figcaption&gt;Solar Eclipse 2020 in Vadodara, Gujarat (Lucky Enough to witness it this¬†year!)&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;This fortnight, I worked around iterating over different designs for redesigning the Dataretriever Clients so that its implementation can be simpler and more general. Generalization here means the ability to inherit most of the methods from the base class itself; therefore minimizing a number of similar methods in the subclasses.&lt;/p&gt;
&lt;h5&gt;Show Method for QueryResponse&lt;/h5&gt;&lt;p&gt;I got&lt;a href="https://github.com/sunpy/sunpy/pull/4309"&gt; PR #4309&lt;/a&gt; merged which solved an old &lt;a href="https://github.com/sunpy/sunpy/issues/556"&gt;Issue #556&lt;/a&gt;. A simple show() function in ~sunpy.net.base_client.BaseQueryResponse enabled QueryResponse objects for Dataretriever, VSO, and JSOC clients to specify the columns to be shown in the¬†result.&lt;/p&gt;
&lt;p&gt;This returns an ~astropy.table.Table instance, so table operations can also be easily performed on the¬†result.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;iframe src="http://openastronomy.org/Universe_OA/posts/2020/06/20200629_1813_abhijeetmanhas/" width="0" height="0" frameborder="0" scrolling="no"&gt;&lt;a href="https://medium.com/media/10fce45866473f2eb6ad74e7f98000eb/href"&gt;https://medium.com/media/10fce45866473f2eb6ad74e7f98000eb/href&lt;/a&gt;&lt;/iframe&gt;&lt;h5&gt;_extract_files_meta method in¬†Scraper&lt;/h5&gt;&lt;p&gt;&lt;a href="https://github.com/sunpy/sunpy/pull/4313"&gt;PR #4313&lt;/a&gt; was merged in sunpy:master that allows the scraper to extract the metadata stored in the file URLs. This function will prove very useful for refactoring the whole ~sunpy.net.dataretriever submodule.&lt;/p&gt;
&lt;p&gt;A new module parse was added in ~sunpy.extern which allowed to specify the extractor which will parse the file URL and return a dict containing the value of attrs like Wavelength, Time, Level, etc. Even the URL is returned by the method, which ensures no changes are to be made in fetch() methods for¬†clients.&lt;/p&gt;
&lt;iframe src="http://openastronomy.org/Universe_OA/posts/2020/06/20200629_1813_abhijeetmanhas/" width="0" height="0" frameborder="0" scrolling="no"&gt;&lt;a href="https://medium.com/media/da15de642196febf9eab940219efac0f/href"&gt;https://medium.com/media/da15de642196febf9eab940219efac0f/href&lt;/a&gt;&lt;/iframe&gt;&lt;h5&gt;Playing with post¬†filters&lt;/h5&gt;&lt;p&gt;Last fortnight I was working with post filters and concatenation of responses for VSO. Last week I dabbled a bit with post-filters for attrs used in all net clients. Using single_dispatch decorator over filter_results enabled post-filtering in dataretriver and VSO. It is pretty similar to the way it is done for ~sunpy.net.vso.attrs.&lt;/p&gt;
&lt;iframe src="http://openastronomy.org/Universe_OA/posts/2020/06/20200629_1813_abhijeetmanhas/" width="0" height="0" frameborder="0" scrolling="no"&gt;&lt;a href="https://medium.com/media/274b4e0b885d17b391589d15c593f046/href"&gt;https://medium.com/media/274b4e0b885d17b391589d15c593f046/href&lt;/a&gt;&lt;/iframe&gt;&lt;h4&gt;Redesigning GenericClient&lt;/h4&gt;&lt;p&gt;So there is a draft &lt;a href="https://github.com/sunpy/sunpy/pull/4321"&gt;PR #4321&lt;/a&gt; where work is in progress for the new implementation for the generalization. QueryResponeBlock is removed from the client.py since by few changes in the QueryResponse enables us to do it all using a dictionary. Similarly &lt;a href="https://github.com/sunpy/sunpy/pull/4321/files"&gt;a lot of methods were removed or changed&lt;/a&gt; under the aim to simplify the two Generic¬†Classes.&lt;/p&gt;
&lt;p&gt;Not only the base class, even the client class were made simple. For simple clients, we are supposed to only define required attrs, optional attrs, a baseurl, and an extractor which makes the search¬†working.&lt;/p&gt;
&lt;p&gt;After this refactoring, the example dataretriever source client class would look something like¬†this:&lt;/p&gt;
&lt;iframe src="http://openastronomy.org/Universe_OA/posts/2020/06/20200629_1813_abhijeetmanhas/" width="0" height="0" frameborder="0" scrolling="no"&gt;&lt;a href="https://medium.com/media/759cceb1f744c525c6a55e80b8f9ecb9/href"&gt;https://medium.com/media/759cceb1f744c525c6a55e80b8f9ecb9/href&lt;/a&gt;&lt;/iframe&gt;&lt;p&gt;Only a class method and few class attributes are sufficient for defining a simple DR¬†client!&lt;/p&gt;
&lt;h5&gt;Hooks for translating attrs&lt;/h5&gt;&lt;p&gt;There are some clients which deviate from generalization. For those clients, it was discussed in a meeting with mentors that post-hooks and pre-hooks for scraper are to be designed which shall perform a translation of attrs provided in the search to their representation in the url. While working around it, I discovered few bugs in fermi_gbm and other clients to be addressed in scraper hooks. Responses for Detector numbers 10 and 11 were never returned because in the url they were represented by na and nb respectively. They will be fixed by translators as a part of pre-hook before passing it to the¬†scraper.&lt;/p&gt;
&lt;h5&gt;Moving Rhessi out from¬†Generic&lt;/h5&gt;&lt;p&gt;Since rhessi didn‚Äôt follow the Generalization as the metadata can‚Äôt just be extracted from the file URL, so it is being implemented as subclass of base_client.&lt;/p&gt;
&lt;p&gt;Every week we move closer and closer to Generalization¬†:). Enjoying the meetings where I and my mentors discuss the pros and cons of different designs of GenericClient!&lt;/p&gt;
&lt;img src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=1879f5dfe436" width="1" height="1"&gt;&lt;/div&gt;</description><category>SunPy</category><guid>http://openastronomy.org/Universe_OA/posts/2020/06/20200629_1813_abhijeetmanhas/</guid><pubDate>Mon, 29 Jun 2020 17:13:52 GMT</pubDate></item><item><title>gsoc_journey.update({‚ÄúChapter 1‚Äù: [‚ÄúCommunity Bonding Phase‚Äù, ‚ÄúStingray‚Äù]})</title><link>http://openastronomy.org/Universe_OA/posts/2020/06/20200629_0011_theand9/</link><dc:creator>Amogh Desai</dc:creator><description>&lt;div&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*WHlJZxJwoGsHr2RSafxoRQ.jpeg"&gt;&lt;figcaption&gt;&lt;strong&gt;‚ÄúAcross the sea of space, the stars are other suns.‚Äù &lt;/strong&gt;~ Carl¬†Sagan&lt;/figcaption&gt;&lt;/figure&gt;&lt;iframe src="https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fwww.youtube.com%2Fembed%2Feb1A4KmVJME%3Ffeature%3Doembed&amp;amp;display_name=YouTube&amp;amp;url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3Deb1A4KmVJME&amp;amp;image=https%3A%2F%2Fi.ytimg.com%2Fvi%2Feb1A4KmVJME%2Fhqdefault.jpg&amp;amp;key=a19fcc184b9711e1b4764040d3dc5c07&amp;amp;type=text%2Fhtml&amp;amp;schema=youtube" width="640" height="480" frameborder="0" scrolling="no"&gt;&lt;a href="https://medium.com/media/09696909e30878c50221a3fd74dca870/href"&gt;https://medium.com/media/09696909e30878c50221a3fd74dca870/href&lt;/a&gt;&lt;/iframe&gt;&lt;p&gt;Firstly, I would like to apologize for not posting a blog for more than a¬†month.&lt;/p&gt;
&lt;p&gt;Secondly, I would again like to apologize as this blog is going to be astronomically jargon-heavy(pun intended). &lt;br&gt;
Now before you decide to just watch the funny Joey video and go watch more Friends episodes; trust me after reading this 7 minute blog you will gain serious bragging rights. After which you can binge Friends to your heart‚Äôs content(I already got my popcorn bowl with me¬†üòâ).&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;h4&gt;Community Bonding Phase and APE‚Ää‚Äî‚Ää17&lt;/h4&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/925/1*r3LeWqbDsz2bz-NfL3zadA.png"&gt;&lt;figcaption&gt;&lt;strong&gt;‚ÄúCommunity is about doing something that makes belonging matter‚Äù&lt;/strong&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Community, as defined by the Cambridge Dictionary is the ‚Äúpeople living in one particular area or people who are considered as a unit because of their common interests, social group, or nationality.‚Äù&lt;/p&gt;
&lt;p&gt;Akin to the communities in the real world, the Open-Source Software community is one of the most diverse and active communities in the world. All Open-Source projects from the Linux Kernel to a niche, newly conceptualized project have several contributors keeping the project alive. &lt;br&gt;
The best part about this online community is that any individual willing to contribute to the project is welcomed irrespective of their caste, creed, gender, race, nationality, level of expertise. &lt;br&gt;
To be a part of a community of zealous, like-minded individuals working towards making the world a better place with software, makes you feel somewhat like a superheroüòÅ.&lt;/p&gt;
&lt;blockquote&gt;&lt;strong&gt;The power of Open-Source is the power of the people &lt;/strong&gt;~ Philippe¬†Kahn&lt;/blockquote&gt;&lt;p&gt;The community bonding phase is probably the most important part of the whole program. A month is given to students to get acquainted with the project community and mentors. Students are expected to get familiarized with the &lt;em&gt;Code of Conduct&lt;/em&gt; and other guidelines such as Contributing, Coding, Testing guidelines.&lt;br&gt;
This is an amazing opportunity to not only plan and research more about one‚Äôs project but also interact with other students of the same/different organization‚Äôs and learn more about their projects.&lt;/p&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*rzgbbfXrjVV2jcr08x8MUg.png"&gt;&lt;figcaption&gt;First Contact. The most exhilarating~2700 seconds of my¬†life&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;I had two calls with my mentor Mr Matteo Bachetti during the community bonding phase. Lucky me, I got a one-to-one introduction to X-Ray Astronomy(with an amazing presentation) from Mr Bachetti himself!!&lt;br&gt;
We discussed the goals, specifics as well as a rough trajectory of the¬†project.&lt;/p&gt;
&lt;p&gt;The community bonding phase gave me an amazing opportunity to not only associate with my peers from OpenAstronomy but also other organizations. I was particularly interested in a few projects from CERN-HSF as well as other projects from various sub-organizations in OpenAstronomy. &lt;br&gt;
Thank you so much, Siddharth Lal, Biswarup Banerjee, Raahul Singh, Kris Stern, Abhijeet Manhas and Sahil Yadav, Honey Gupta, Prateek Kumar Agnihotri and Pranath Reddy for answering my persistent and often novice-level questions. You guys are awesome!!&lt;/p&gt;
&lt;p&gt;Towards the end of the community bonding phase, I started working on updating stingray to APE-17(view my PR &lt;a href="https://github.com/StingraySoftware/stingray/pull/469"&gt;here&lt;/a&gt;). It was my first major PR(For all the non-techies out there a Pull Request(PR) is a proposal to implement changes to the main codebase to squash a bug or add a new feature). Looking at the status of the PR changed to ‚Äú&lt;strong&gt;merged&lt;/strong&gt;‚Äù gave me an unprecedented level of gratification. &lt;em&gt;#justprogrammerthings&lt;/em&gt;&lt;br&gt;
I will not bore you with the technical aspects of APE-17 but if you wish to learn more about it, here‚Äôs a &lt;a href="https://github.com/StingraySoftware/stingray/files/4718995/APE17.Update.pdf"&gt;summarized document I¬†created&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;X-ray Astronomy 101 with¬†stingray&lt;/h4&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/879/1*EsYpWW63Ui-bHMtjnIHjtQ.png"&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Disclaimer: &lt;/strong&gt;I am not an expert at X-ray Astronomy, not even by a long shot(Just a month‚Äôs experience). I am a Computer Science techie, passionate about space and great at googling stuff¬†üòÅ.&lt;/p&gt;
&lt;p&gt;Now the part that all of you have been waiting for, the part that will give you the ultimate bragging rights of learning something new, &lt;em&gt;being productive&lt;/em&gt; in these lazy lockdown times, presenting to you&lt;em&gt;(insert drum roll) &lt;/em&gt;&lt;br&gt;
&lt;strong&gt;X-ray Astronomy 101 with stingray.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;1. What is stingray? What does it¬†do?&lt;/p&gt;
&lt;p&gt;Stingray is a community-developed spectral-timing software package in Python for astrophysical data. It provides a basis for advanced spectral-timing analysis with a correct statistical framework while also being open-source.&lt;br&gt;
Stingray provides functionalities such as:&lt;br&gt;
a. Constructing light curves from event data and performing various operations on light curves (e.g. add, subtract, join, truncate)&lt;br&gt;
b. Good Time Interval operations&lt;br&gt;
c. Creating periodograms(power spectra) and cross spectra&lt;br&gt;
and many¬†more.&lt;/p&gt;
&lt;p&gt;2. So well what does all of this¬†mean?&lt;/p&gt;
&lt;p&gt;I apologize for the abrupt deep dive into the realm of long and daunting words that make zero sense at the moment. But please bear with me for a moment, once we are done with the basic you will truly appreciate the role that stingray¬†plays.&lt;/p&gt;
&lt;p&gt;So let‚Äôs start with the¬†basics.&lt;/p&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/780/1*c_HQHP_uPGD4z6o11j7veg.png"&gt;&lt;figcaption&gt;A time series is a simple graph that can be plotted for any values eg. temperature, rainfall, stock price¬†etc.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;a. &lt;strong&gt;Time Series:&lt;/strong&gt; It is a sequence of observations recorded at a succession of time intervals. In general, time series are characterized by the interdependence of its values. This means that the value of the series at some time &lt;strong&gt;t&lt;/strong&gt; is generally not independent of its value at, say,¬†&lt;strong&gt;t‚àí1&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;b.&lt;strong&gt; Time Series Analysis:&lt;/strong&gt; It is a statistical technique that deals with gaining insights from periodic or stochastic(a fancy way of saying random, aperiodic) time-series data.&lt;/p&gt;
&lt;p&gt;Now let‚Äôs learn some astronomical terms:&lt;/p&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/850/1*yMWqnSRF06lxoYKptQ4d-A.png"&gt;&lt;figcaption&gt;FFT I am looking at¬†you&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;a. &lt;strong&gt;Timing Analysis&lt;/strong&gt;: Many time series show periodic behaviour. This periodic behaviour can be very complex. Spectral analysis is a technique that allows us to discover underlying periodicities by decomposing the complex signal into simpler parts. To perform spectral analysis, we first must transform data from the time domain to the frequency domain. &lt;br&gt;
Hence spectral analysis can be defined as decomposing a stationary time series {&lt;em&gt;xT}&lt;/em&gt; into a combination of sinusoids(sine waves), with a random (and uncorrelated) coefficient; essentially analysis in the frequency domain.&lt;/p&gt;
&lt;p&gt;b. &lt;strong&gt;Good Time Intervals (GTI‚Äôs)&lt;/strong&gt;: When observing a stellar object with a satellite, data is accumulated by observing the source with short exposures over time or collecting single photons(light particles) with their arrival time.&lt;br&gt;
While recording observations, there will be times when everything is working perfectly. At other times we might have obstructions from the Earth that hinder our ability to observe the source properly.&lt;br&gt;
Good time intervals (GTIs) are the time intervals where instruments are working well and the source is perfectly visible.&lt;/p&gt;
&lt;p&gt;c. &lt;strong&gt;Light Curves&lt;/strong&gt;: Light curves are graphs that show the brightness of an object over a period of time. Images show from the part of an object from where light is emitted. Another piece of information we have about light is the time when it reaches the detector. Astronomers use this ‚Äútiming‚Äù information to create light curves and perform timing analysis. &lt;br&gt;
They are simply graphs of brightness (Y-axis) vs. time (X-axis). Brightness increases as you go up the graph and time advances as you move to the right.&lt;br&gt;
eg. The following lightcurve can be generated with the values from the table on the left. The change in brightness is periodic.&lt;/p&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/860/1*FNFYTegivTDTnsfqis1Tag.jpeg"&gt;&lt;/figure&gt;&lt;p&gt;We can generate similar light curves for studying any part of the light spectrum eg. X-Rays. The record of changes in brightness that a light curve provides can help astronomers understand processes at work within the object they are studying and identify specific categories of stellar¬†events.&lt;/p&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/591/0*r2NyyR6RtBfhevGq.png"&gt;&lt;/figure&gt;&lt;p&gt;d.&lt;strong&gt; Spectral Density/Power Spectra&lt;/strong&gt;: The power spectra of a time series {&lt;em&gt;xT} &lt;/em&gt;describes the distribution of power into the frequency components of that signal. When these signals are viewed in the form of a frequency spectrum, certain aspects of the received signals or the underlying processes producing them are revealed.&lt;/p&gt;
&lt;p&gt;e.&lt;strong&gt; Power Spectral Density Function&lt;/strong&gt;: A Power spectral density function (PSD) shows the number of energy variations as a function of frequency. In other words, it shows at which frequencies are variations strong,¬†weak.&lt;/p&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/582/0*ZYcuX1JdLSPTjPeM.png"&gt;&lt;/figure&gt;&lt;p&gt;f. &lt;strong&gt;Cross Spectra&lt;/strong&gt;: Cross spectral analysis allows one to determine the relationship between two time-series as a function of frequency. Normally, we wish to compare two time-series along their peaks to see if these signals are related to one another at the same frequency and if so, what is the phase relationship between them. Even if two signals look identical we wish to check their periodicity and understand how they are related.&lt;br&gt;
The Cross spectrum is a frequency domain analysis of the cross-correlation (how two lightcurves are related) or cross-covariance(how two lightcurves are related if one of them is linearly transformed eg. shifted in time).&lt;br&gt;
For further reference check this out: &lt;a href="https://atmos.washington.edu/~dennis/552_Notes_6c.pdf"&gt;https://atmos.washington.edu/~dennis/552_Notes_6c.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;3. How does stingray contribute to all of this confusing stuff?&lt;/p&gt;
&lt;p&gt;Stingray implements all of these complex functions in a single easy to use package. It has various methods and classes such as lightcurve, powerspectrum, crossspectrum.&lt;br&gt;
Stingray also provides a &lt;em&gt;HENDRICS &lt;/em&gt;CLI and &lt;em&gt;dave &lt;/em&gt;GUI interface for abstract analysis.&lt;/p&gt;
&lt;p&gt;Woohoo!!üéâüéâ you made it through.&lt;br&gt;
Now if all of this intrigues you as much as it did me, you can go through the references mentioned below and the &lt;a href="https://github.com/StingraySoftware/notebooks"&gt;stingray notebooks &lt;/a&gt;that demonstrate the functionality mentioned above or even fork the repository and tinker around with the code yourself(&lt;strong&gt;Highly Recommended!&lt;/strong&gt;).&lt;/p&gt;
&lt;p&gt;Thank you soo much for giving it a read. Please comment and leave a clap if you liked the article. Feel free to reach out to me on &lt;a href="https://www.linkedin.com/in/theand9/"&gt;Linkedin&lt;/a&gt;. &lt;br&gt;
Have an amazing day!! &lt;strong&gt;You are awesome!!!&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;&lt;strong&gt;References:&lt;/strong&gt;&lt;/blockquote&gt;&lt;blockquote&gt;1. &lt;a href="http://web.stanford.edu/class/earthsys214/notes/series.html"&gt;http://web.stanford.edu/class/earthsys214/notes/series.html &lt;/a&gt;&lt;br&gt;
2. &lt;a href="https://www.investopedia.com/terms/t/timeseries.asp.."&gt;https://www.investopedia.com/terms/t/timeseries.asp&lt;/a&gt;&lt;br&gt;
3. &lt;a href="https://imagine.gsfc.nasa.gov/science/toolbox/timing1.html.."&gt;https://imagine.gsfc.nasa.gov/science/toolbox/timing1.html&lt;/a&gt;&lt;br&gt;
4. &lt;a href="http://coolwiki.ipac.caltech.edu/index.php/What_is_a_periodogram"&gt;http://coolwiki.ipac.caltech.edu/index.php/What_is_a_periodogram&lt;/a&gt;&lt;/blockquote&gt;&lt;img src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=f3f95dffe246" width="1" height="1"&gt;&lt;/div&gt;</description><category>stingray</category><guid>http://openastronomy.org/Universe_OA/posts/2020/06/20200629_0011_theand9/</guid><pubDate>Sun, 28 Jun 2020 23:11:13 GMT</pubDate></item><item><title>Chapter 2: Inquisition</title><link>http://openastronomy.org/Universe_OA/posts/2020/06/20200628_2315_raahul-singh/</link><dc:creator>Raahul Singh</dc:creator><description>&lt;div&gt;&lt;h5&gt;Does AR Complexity correlate to Flaring Activity?&lt;/h5&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1020/1*UYJ3RzoWUcEgQUhWyo9uAA.jpeg"&gt;&lt;figcaption&gt;Rhododendrons flowering in the mountains. The State Flower of my state, Uttarakhand. The &lt;strong&gt;rhododendron&lt;/strong&gt; is native to sunny areas, it symbolizes beauty and energy. With its symbolism of optimism and cheer, it also serves as a symbol of love and the general positivity of the mountains.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;There has never been a better time to help scientists understand the mysteries of the¬†sun.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.scientificamerican.com/gallery/turbulent-inner-life-of-a-sunspot-uncovered/"&gt;‚ÄòSunspots&lt;/a&gt;‚Äô and ‚Äò&lt;a href="https://www.scientificamerican.com/citizen-science/solar-stormwatch/"&gt;solar storms&lt;/a&gt;‚Äô are the feature of an ambitious project launched internationally by astrophysicists at Trinity College Dublin. Citizen scientists work as part of a global team to better understand sunspot and solar storm phenomena and their impacts on Earth. They do this by ‚Äòrating‚Äô the relative complexity of each sunspot image they see on the &lt;a href="http://www.sunspotter.org/"&gt;Sunspotter Web site&lt;/a&gt;, based on its size, shape and arrangement of ‚Äòmagnetic blobs‚Äô. &lt;a href="http://www.sunspotter.org/?utm_source=Newsletter&amp;amp;utm_medium=Email&amp;amp;utm_campaign=SunspotterLaunch&amp;amp;utm_content=T"&gt;Sunspotter&lt;/a&gt; is essentially a game of hot-or-not for sunspot data; citizen scientists are shown two images of sunspot groups and asked which is more complex. This is extremely useful in helping astronomers understand the physics of our star, the Sun.&lt;br&gt;
&lt;br&gt;
&lt;!-- TEASER_END --&gt;
Researchers cannot just use computers to classify all of this data because ‚Äòcomplexity‚Äô is not easily quantifiable. &lt;br&gt;
This project is part of the ‚Äò&lt;a href="https://www.zooniverse.org/"&gt;Zooniverse&lt;/a&gt;‚Äô, a Web portal devoted to citizen science projects and which has more than 1 million volunteers.&lt;/p&gt;
&lt;p&gt;Now the question arises, does this &lt;strong&gt;complexity&lt;/strong&gt; actually correlate to &lt;strong&gt;Flare Activity&lt;/strong&gt;?&lt;/p&gt;
&lt;p&gt;To find the answer, we must leverage the power of Statistical Hypothesis Testing.&lt;/p&gt;
&lt;h4&gt;Statistical Hypothesis Testing&lt;/h4&gt;&lt;p&gt;A &lt;strong&gt;statistical hypothesis&lt;/strong&gt;, sometimes called &lt;strong&gt;confirmatory data analysis&lt;/strong&gt;, is a &lt;a href="https://en.wikipedia.org/wiki/Hypothesis"&gt;hypothesis&lt;/a&gt; that is testable on the basis of &lt;a href="https://en.wikipedia.org/wiki/Observable_variable"&gt;observing&lt;/a&gt; a process that is &lt;a href="https://en.wikipedia.org/wiki/Statistical_model"&gt;modeled&lt;/a&gt; via a set of &lt;a href="https://en.wikipedia.org/wiki/Random_variable"&gt;random variables&lt;/a&gt;. A &lt;strong&gt;statistical hypothesis test&lt;/strong&gt; is a method of &lt;a href="https://en.wikipedia.org/wiki/Statistical_inference"&gt;statistical inference&lt;/a&gt;. Commonly, two statistical data sets are compared, or a data set obtained by sampling is compared against a synthetic data set from an idealized model. An &lt;a href="https://en.wikipedia.org/wiki/Alternative_hypothesis"&gt;alternative&lt;/a&gt; hypothesis is proposed for the statistical-relationship between the two data-sets, and is compared to an idealized null hypothesis that proposes no relationship between these two data-sets. This comparison is deemed &lt;a href="https://en.wikipedia.org/wiki/Statistically_significant"&gt;&lt;em&gt;statistically significant&lt;/em&gt;&lt;/a&gt; if the relationship between the data-sets would be an unlikely realization of the &lt;a href="https://en.wikipedia.org/wiki/Null_hypothesis"&gt;null hypothesis&lt;/a&gt; according to a threshold probability‚Ää‚Äî‚Ääthe significance level. Hypothesis tests are used when determining what outcomes of a study would lead to a rejection of the null hypothesis for a pre-specified level of significance.&lt;/p&gt;
&lt;h4&gt;The Null Hypothesis&lt;/h4&gt;&lt;p&gt;In &lt;a href="https://en.wikipedia.org/wiki/Inferential_statistics"&gt;inferential statistics&lt;/a&gt;, the &lt;strong&gt;null hypothesis&lt;/strong&gt; is a general statement or default position that there is no relationship between two measured phenomena or no association among¬†groups.&lt;/p&gt;
&lt;p&gt;In other words nothing interesting is going on. The data on complexity has no relationship with the data on Flaring Activity.&lt;/p&gt;
&lt;p&gt;Our primary work here is to find evidence against the Null Hypothesis.&lt;/p&gt;
&lt;h4&gt;The Alternative Hypothesis&lt;/h4&gt;&lt;p&gt;In &lt;a href="https://en.wikipedia.org/wiki/Statistical_hypothesis_testing"&gt;statistical hypothesis testing&lt;/a&gt;, the &lt;strong&gt;alternative hypothesis&lt;/strong&gt; is a position that states something is happening, a new theory is preferred instead of an old one (&lt;a href="https://en.wikipedia.org/wiki/Null_hypothesis"&gt;null hypothesis&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;For our present study, the alternative hypothesis states that there indeed is&lt;strong&gt; &lt;/strong&gt;a&lt;strong&gt; positive correlation &lt;/strong&gt;between&lt;strong&gt; AR complexity and Flaring Activity.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;It is this hypothesis that gets proved if we can successfully disregard the Null Hypothesis&lt;/p&gt;
&lt;p&gt;I take a statistical approach to determine if the complexity indeed does correlate to Solar Flare Activity.&lt;/p&gt;
&lt;h4&gt;p-Value&lt;/h4&gt;&lt;p&gt;In &lt;a href="https://en.wikipedia.org/wiki/Statistical_hypothesis_testing"&gt;statistical hypothesis testing&lt;/a&gt;, the &lt;strong&gt;&lt;em&gt;p&lt;/em&gt;-value &lt;/strong&gt;or &lt;strong&gt;probability value&lt;/strong&gt; is the best probability of obtaining test results at least as extreme as the &lt;a href="https://en.wikipedia.org/wiki/Realization_(probability)"&gt;results actually observed&lt;/a&gt;, assuming that the &lt;a href="https://en.wikipedia.org/wiki/Null_hypothesis"&gt;null hypothesis&lt;/a&gt; is correct. A very small &lt;em&gt;p&lt;/em&gt;-value means that the observed &lt;a href="https://en.wikipedia.org/wiki/Outcome_(probability)"&gt;outcome&lt;/a&gt; is possible but not very likely under the null hypothesis, even under the best explanation which is possible under that hypothesis.&lt;br&gt;
A smaller p-value would indicate that the Alternative Hypothesis is more likely than the Null Hypothesis. A small p-value is necessary but not sufficient to disregard the Null Hypothesis.&lt;/p&gt;
&lt;p&gt;The task at hand, thus, is to find the correlation between the AR complexity and the Flaring Activity, should any exist, and to find the p-value for the correlation.&lt;/p&gt;
&lt;h5&gt;To calculate the correlation and the associated p-value,&lt;/h5&gt;&lt;iframe src="http://openastronomy.org/Universe_OA/posts/2020/06/20200628_2315_raahul-singh/" width="0" height="0" frameborder="0" scrolling="no"&gt;&lt;a href="https://medium.com/media/2e5b9911891a95b71ac8552bf4a33585/href"&gt;https://medium.com/media/2e5b9911891a95b71ac8552bf4a33585/href&lt;/a&gt;&lt;/iframe&gt;&lt;iframe src="http://openastronomy.org/Universe_OA/posts/2020/06/20200628_2315_raahul-singh/" width="0" height="0" frameborder="0" scrolling="no"&gt;&lt;a href="https://medium.com/media/9edb4aec3096ee9f1e50d2f69850bc4d/href"&gt;https://medium.com/media/9edb4aec3096ee9f1e50d2f69850bc4d/href&lt;/a&gt;&lt;/iframe&gt;&lt;iframe src="http://openastronomy.org/Universe_OA/posts/2020/06/20200628_2315_raahul-singh/" width="0" height="0" frameborder="0" scrolling="no"&gt;&lt;a href="https://medium.com/media/80c3c7f9805376f4fdfb9a6cc1c377bb/href"&gt;https://medium.com/media/80c3c7f9805376f4fdfb9a6cc1c377bb/href&lt;/a&gt;&lt;/iframe&gt;&lt;iframe src="http://openastronomy.org/Universe_OA/posts/2020/06/20200628_2315_raahul-singh/" width="0" height="0" frameborder="0" scrolling="no"&gt;&lt;a href="https://medium.com/media/a13636850986a3fbebbf8db3c25da0bd/href"&gt;https://medium.com/media/a13636850986a3fbebbf8db3c25da0bd/href&lt;/a&gt;&lt;/iframe&gt;&lt;p&gt;Now that we have the DataFrames, we move on to use Point-Biserial Correlation.&lt;/p&gt;
&lt;h4&gt;Point-Biserial Correlation&lt;/h4&gt;&lt;p&gt;A point-biserial correlation is used to measure the strength and direction of the association that exists between one continuous variable and one dichotomous variable. It is a special case of the Pearson‚Äôs product-moment correlation, which is applied when you have two continuous variables, whereas in this case one of the variables is measured on a dichotomous scale.&lt;/p&gt;
&lt;h4&gt;Assumptions for using Point-Biserial Correlation&lt;/h4&gt;&lt;h5&gt;Assumption 1&lt;/h5&gt;&lt;blockquote&gt;One of the two variables should be measured on a continuous scale. In this analysis, the &lt;strong&gt;Complexity&lt;/strong&gt; is continuous.&lt;/blockquote&gt;&lt;h5&gt;Assumption 2&lt;/h5&gt;&lt;blockquote&gt;The other variable should be dichotomous. In this analysis, the whether an AR &lt;strong&gt;flares&lt;/strong&gt; is dichotomous, &lt;strong&gt;&lt;em&gt;0&lt;/em&gt;&lt;/strong&gt; denoting no flaring and &lt;strong&gt;&lt;em&gt;1&lt;/em&gt;&lt;/strong&gt; denoting¬†flaring.&lt;/blockquote&gt;&lt;h5&gt;Assumption 3&lt;/h5&gt;&lt;blockquote&gt;The continuous variable should have equal variances for each category of the dichotomous variable.&lt;/blockquote&gt;&lt;h5&gt;Assumption 4&lt;/h5&gt;&lt;blockquote&gt;There should be no outliers for the continuous variable for each category of the dichotomous variable.&lt;/blockquote&gt;&lt;h5&gt;Assumption 5&lt;/h5&gt;&lt;blockquote&gt;The continuous variable should be approximately normally distributed for each category of the dichotomous variable.&lt;/blockquote&gt;&lt;p&gt;Having already satisfied assumptions 1 and¬†2,&lt;/p&gt;
&lt;h5&gt;For Assumption 3&lt;/h5&gt;&lt;iframe src="http://openastronomy.org/Universe_OA/posts/2020/06/20200628_2315_raahul-singh/" width="0" height="0" frameborder="0" scrolling="no"&gt;&lt;a href="https://medium.com/media/ef13a7a8d2ae7170f901d2653794b912/href"&gt;https://medium.com/media/ef13a7a8d2ae7170f901d2653794b912/href&lt;/a&gt;&lt;/iframe&gt;&lt;h5&gt;Thus Assumption 3¬†holds.&lt;/h5&gt;&lt;blockquote&gt;Continuous variable in both positive and negative classes has equal variance.&lt;/blockquote&gt;&lt;h5&gt;For Assumption 4&lt;/h5&gt;&lt;iframe src="http://openastronomy.org/Universe_OA/posts/2020/06/20200628_2315_raahul-singh/" width="0" height="0" frameborder="0" scrolling="no"&gt;&lt;a href="https://medium.com/media/42d552cf02963d648621c29a8ee0c652/href"&gt;https://medium.com/media/42d552cf02963d648621c29a8ee0c652/href&lt;/a&gt;&lt;/iframe&gt;&lt;p&gt;This script gives the following two¬†plots:&lt;/p&gt;
&lt;p&gt;In both plots &lt;strong&gt;&lt;em&gt;1 &lt;/em&gt;&lt;/strong&gt;denotes that a flare has been observed and&lt;strong&gt;&lt;em&gt; 0 &lt;/em&gt;&lt;/strong&gt;denotes no flaring activity is observed.&lt;/p&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/999/1*5qHyB09_s4XL75Q9TrnLAw.png"&gt;&lt;figcaption&gt;Box plot&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/999/1*KEp3Tx0v27ftK46duSSFfw.png"&gt;&lt;figcaption&gt;Violin Plot&lt;/figcaption&gt;&lt;/figure&gt;&lt;blockquote&gt;These plots show some outliers. For the current analysis, it is assumed that the outliers do not affect the correlation significantly. It is of interest to see the quantitative effect that the outliers have on the overall forecasting.&lt;/blockquote&gt;&lt;h5&gt;For Assumption 5&lt;/h5&gt;&lt;h5&gt;Plotting the distribution of positive and negative¬†classes&lt;/h5&gt;&lt;iframe src="http://openastronomy.org/Universe_OA/posts/2020/06/20200628_2315_raahul-singh/" width="0" height="0" frameborder="0" scrolling="no"&gt;&lt;a href="https://medium.com/media/b4c3a28d823e308a396667756e76a167/href"&gt;https://medium.com/media/b4c3a28d823e308a396667756e76a167/href&lt;/a&gt;&lt;/iframe&gt;&lt;p&gt;Which gives,&lt;/p&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/990/1*OxNolvY3nxrDCA9XqWbUGQ.png"&gt;&lt;figcaption&gt;Distribution plots for both¬†classes&lt;/figcaption&gt;&lt;/figure&gt;&lt;blockquote&gt;From the distribution plots, the distribution of the normalized complexity in the negative and positive classes can be considered Gaussian.&lt;/blockquote&gt;&lt;h5&gt;Thus Assumption 5¬†holds.&lt;/h5&gt;&lt;h4&gt;Point-Biserial Correlation&lt;/h4&gt;&lt;p&gt;Since all the assumptions are satisfied, we move on to the actual correlation.&lt;/p&gt;
&lt;iframe src="http://openastronomy.org/Universe_OA/posts/2020/06/20200628_2315_raahul-singh/" width="0" height="0" frameborder="0" scrolling="no"&gt;&lt;a href="https://medium.com/media/4a0e4ec72ca37503044c4a6fd141e54a/href"&gt;https://medium.com/media/4a0e4ec72ca37503044c4a6fd141e54a/href&lt;/a&gt;&lt;/iframe&gt;&lt;p&gt;Thus,&lt;/p&gt;
&lt;blockquote&gt;The Point-Biserial Correlation shows a moderate positive correlation between AR complexity and Flare Production.&lt;/blockquote&gt;&lt;p&gt;The moderate positive correlation of 0.45 indicates that there indeed exists a positive relationship between AR complexity and Flare activity.&lt;/p&gt;
&lt;p&gt;Although the negligible &lt;strong&gt;p-value &lt;/strong&gt;of&lt;strong&gt; &lt;/strong&gt;0.0&lt;strong&gt; &lt;/strong&gt;is necessary to disregard the the Null Hypothesis, it is not sufficient.&lt;/p&gt;
&lt;p&gt;My mentors and I are devising a strategy to firmly establish the&lt;strong&gt; alternative hypothesis.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This post marks the end of the first month of my GSoC journey, and my oh my what a month it has been!&lt;br&gt;
I am used to working long hours but somehow working on Pythia always makes these long hours pass me by in¬†minutes.&lt;/p&gt;
&lt;p&gt;July brings with it, Deep Learning. The next month will be the most fun as I get to play around with neural networks and actually work on forecasting flares!&lt;br&gt;
I just hope the gods that govern CUDA and PyTorch are benevolent and do not curse me with exploding gradients.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;:)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;References¬†&lt;/em&gt;: &lt;br&gt;
1) &lt;a href="https://www.scientificamerican.com/citizen-science/zooniverse-sunspotter/"&gt;&lt;em&gt;On Sunspotter&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;3) &lt;a href="https://en.wikipedia.org/wiki/Statistical_inference"&gt;&lt;em&gt;Statistical Inference and related sub¬†topics&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;3) &lt;a href="https://statistics.laerd.com/spss-tutorials/point-biserial-correlation-using-spss-statistics.php"&gt;&lt;em&gt;Point-Biserial correlation&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;
&lt;img src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=dd46de0863f6" width="1" height="1"&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://blog.usejournal.com/chapter-2-inquisition-dd46de0863f6"&gt;Chapter 2: Inquisition&lt;/a&gt; was originally published in &lt;a href="https://blog.usejournal.com"&gt;Noteworthy - The Journal Blog&lt;/a&gt; on Medium, where people are continuing the conversation by highlighting and responding to this story.&lt;/p&gt;&lt;/div&gt;</description><category>SunPy</category><guid>http://openastronomy.org/Universe_OA/posts/2020/06/20200628_2315_raahul-singh/</guid><pubDate>Sun, 28 Jun 2020 22:15:06 GMT</pubDate></item><item><title>Week 3 &amp; 4: First blood</title><link>http://openastronomy.org/Universe_OA/posts/2020/06/20200628_1322_sahilyadav27/</link><dc:creator>Sahil Yadav</dc:creator><description>&lt;div&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/680/1*eVG6uotsjTa5V092bqJ_uw.jpeg"&gt;&lt;figcaption&gt;‚ÄúMagic‚Äù&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Since the last blog post, where there was a discussion about creating a script to convert the ROOT file into an HDF5 file with the CTA ML data format. So, during week 3 and 4 I was working on making this script. There were a few issues in this conversion.&lt;/p&gt;
&lt;p&gt;In the current DL1DataHandler, the event number is created conveniently in accordance with CTA data. But, the MAGIC data uses a different way to store event numbers. There are 2 arrays for each camera, one for the EvtNumber and another for StereoEvtNumber. The StereoEvtNumber array is mapped from the EvtNumber array. So, I used all the stereo events and stored their values in the HDF5 file. Mono study can be also done on these stereo events. Since MAGIC doesn‚Äôt currently do mono analysis on events triggering only one telescope, that part is currently omitted.&lt;/p&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*aDisON-sEtx0T9-w9Lvkeg.png"&gt;&lt;/figure&gt;&lt;p&gt;So, now that this mapping is figured, we also mapped all the variables required in the HDF5 file with them in the ROOT file. Once everything was set up, I tried reading this converted file using the DL1DataReader. The first run yielded amazing¬†results.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/365/1*gwcmu83NnKO8jYQUFYl5yA.png"&gt;&lt;figcaption&gt;First run output for MAGIC cam 1 and 2 from the converted HDF5¬†file&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;So now I made &lt;a href="https://github.com/cta-observatory/dl1-data-handler/pull/90"&gt;PR #90&lt;/a&gt; to add this script to the DL1DataHandler. There are a few additions, like reading a runlist instead of filename, adding metadata, etc.&lt;/p&gt;
&lt;p&gt;Hence, the first milestone of the project is complete along with the first¬†month.&lt;/p&gt;
&lt;img src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=dc1ba79de370" width="1" height="1"&gt;&lt;/div&gt;</description><category>CTLearn</category><guid>http://openastronomy.org/Universe_OA/posts/2020/06/20200628_1322_sahilyadav27/</guid><pubDate>Sun, 28 Jun 2020 12:22:03 GMT</pubDate></item><item><title>What we've been working on these days!</title><link>http://openastronomy.org/Universe_OA/posts/2020/06/20200628_0700_meuge/</link><dc:creator>Meuge</dc:creator><description>&lt;div&gt;&lt;p&gt;Hey, folks! I hope everyone is okay out there. Today, I am going to explain a little bit about &lt;strong&gt;Repeat ground track orbits&lt;/strong&gt;, and the value that lies behind.
Orbits with repeating ground tracks play a significant role in space engineering. Ground tracks that repeat according to any pattern have meaningful applications in remote sensing missions, reconnaissance missions, and numerous rendezvous and docking opportunities with an orbiting spacecraft. Since they overfly the same points on the planet‚Äôs surface every repeat cycle, such as those studying gravity, the atmosphere, or the movement of the polar ice cap.&lt;/p&gt;
&lt;p&gt;&lt;img alt="mind-blown" src="https://media.giphy.com/media/OK27wINdQS5YQ/giphy.gif"&gt;&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;p&gt;So as you might imagine, this is amazing. In one way, the data we consume relies on these orbits. As mentioned before, Repeat ground track (RGT) orbits allows a satellite to reobserve the same area after a repeat cycle. &lt;/p&gt;
&lt;p&gt;&lt;img alt="repeat-ground-track" src="https://www.iceye.com/hs-fs/hubfs/new-pages-website-2019/Img%20(no%20adding)/Sat%20Data%20-%20constellation.gif?width=450&amp;amp;name=Sat%20Data%20-%20constellation.gif"&gt;&lt;/p&gt;
&lt;h2&gt;So how do we ‚Ä¶&lt;/h2&gt;&lt;/div&gt;</description><category>poliastro</category><guid>http://openastronomy.org/Universe_OA/posts/2020/06/20200628_0700_meuge/</guid><pubDate>Sun, 28 Jun 2020 06:00:00 GMT</pubDate></item><item><title>To Infinity and Beyond!</title><link>http://openastronomy.org/Universe_OA/posts/2020/06/20200627_1945_meuge/</link><dc:creator>Meuge</dc:creator><description>&lt;div&gt;&lt;p&gt;Hey folks! It's been a while, but here I am to keep you posted about what we've been up to these last days. &lt;/p&gt;
&lt;p&gt;&lt;img alt="news" src="https://media.giphy.com/media/3o84sJXOIrnjvlwnF6/giphy.gif"&gt;&lt;/p&gt;
&lt;h2&gt;What have we been up to?&lt;/h2&gt;
&lt;!-- TEASER_END --&gt;
&lt;p&gt;We began the coding period with a video call with the mentors, as you might already know, &lt;strong&gt;JuanLu&lt;/strong&gt; and &lt;strong&gt;Jorge&lt;/strong&gt;. We got to know each other a little better, and we started to design what was ahead of our path.&lt;/p&gt;
&lt;p&gt;&lt;img alt="future" src="https://media.giphy.com/media/KZocN3LfuqktW/giphy.gif"&gt;&lt;/p&gt;
&lt;p&gt;But, before dropping any line of code, we first had to think about what would be the best way to integrate the new features to &lt;strong&gt;Poliastro community&lt;/strong&gt; in order to capture the desired requirements from an end-user perspective. After some deliberation, we came up with the idea of adding two new objects. &lt;/p&gt;
&lt;p&gt;&lt;img alt="Spock" src="https://media.giphy.com/media/sBl8Fowq0ErFC/giphy.gif"&gt;&lt;/p&gt;
&lt;p&gt;By now, I hope to have your attention as well as Spock's. So we created &lt;em&gt;EarthSatellite&lt;/em&gt; and &lt;em&gt;Spacecraft&lt;/em&gt;. Both ‚Ä¶&lt;/p&gt;&lt;/div&gt;</description><category>poliastro</category><guid>http://openastronomy.org/Universe_OA/posts/2020/06/20200627_1945_meuge/</guid><pubDate>Sat, 27 Jun 2020 18:45:00 GMT</pubDate></item><item><title>2 Weeks at DiRAC</title><link>http://openastronomy.org/Universe_OA/posts/2020/06/20200620_1723_techguybiswa/</link><dc:creator>Biswarup Banerjee</dc:creator><description>&lt;div&gt;&lt;p&gt;&lt;strong&gt;BiWeekly GSoC Updates Blog¬†Post&lt;/strong&gt;&lt;/p&gt;
&lt;figure&gt;&lt;img alt="Data Intensive Research in Astronjomy and Astrophysics" src="https://cdn-images-1.medium.com/max/1024/1*Ek9a1DbEALyFlh8ueU56wQ.jpeg"&gt;&lt;figcaption&gt;Data-Intensive Research in Astronomy and Cosmology&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;In all my previous internships/contract-work I have worked with only the web stack and that too on the web front end specifically.&lt;br&gt;
All through the past years, I have been part of creating large scale consumer-facing web apps mostly with Javascript and related frameworks like React, Vue, and¬†Angular.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;p&gt;But when I started working with DiRAC‚Äôs Data Engineering team, I had to work on a totally different tech¬†stack!&lt;/p&gt;
&lt;p&gt;The Data Engineering team worked on Jupyter Lab and Jupyter Notebooks. They also worked mostly with Python/Go-related tech stack and frameworks and on very impressive DevOps stuff on AWS and also on their own EPYC¬†servers.&lt;/p&gt;
&lt;p&gt;Although I had experience in Python mostly from solving LeetCode questions, but not a development experience with Python Frameworks. And I never heard of the Jupyter ecosystem before working at DiRAC. And the biggest DevOps stuff I have had ever done was hosting my projects on simple hosting services like¬†Netlify.&lt;/p&gt;
&lt;blockquote&gt;So all these terms like Jupyter Notebook, Jupyter Lab, EPYC, Pyspark, Tornado, were totally alien to¬†me.&lt;/blockquote&gt;&lt;p&gt;It was a new learning curve for me but definitely very interesting, intriguing, and challenging at the same¬†time.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Also and most importantly, my mentors were super supportive and they communicated everything to the minutest details and helped me with links of all the necessary documentation and explained the workflows over video¬†calls.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Well, apart from tech stack, I came to know a lot of people from DiRAC as we interacted over the weekly data engineering meetings. &lt;br&gt;
I had interactions with Colin, Dino, Andy, Chris, and Brigitta who are working on the Data Engineering team.&lt;/p&gt;
&lt;p&gt;Regarding my GSoC project, we are trying to build an MVP and launch a minimal version by the end of next¬†week.&lt;/p&gt;
&lt;img src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=9525ec15bc20" width="1" height="1"&gt;&lt;/div&gt;</description><category>astronomy-commons</category><guid>http://openastronomy.org/Universe_OA/posts/2020/06/20200620_1723_techguybiswa/</guid><pubDate>Sat, 20 Jun 2020 16:23:18 GMT</pubDate></item><item><title>Week 1 &amp; 2: Coding Officially Begins!</title><link>http://openastronomy.org/Universe_OA/posts/2020/06/20200615_1804_siddharthlal25/</link><dc:creator>siddharthlal25</dc:creator><description>&lt;div&gt;&lt;h3 id="hey-sid-did-the-coding-period-officially-begin"&gt;&lt;em&gt;Hey Sid, did the coding period officially begin?&lt;/em&gt;&lt;/h3&gt;

&lt;p&gt;The community bonding period ended by the end of last month and the coding period officially began, I started to work on basic structure of the package and setting up the (not so user-friendly, PS: from astronomer‚Äôs perspective) interface for the image reduction methods.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;

&lt;h3 id="hey-what-did-you-build-in-these-two-weeks"&gt;&lt;em&gt;Hey, what did you build in these two weeks?&lt;/em&gt;&lt;/h3&gt;

&lt;p&gt;I have set up the basic methods required for processing of astronomical images, let me explain it to you one by one:&lt;/p&gt;

&lt;p&gt;The first method implemented was &lt;code class="language-plaintext highlighter-rouge"&gt;subtract_bias&lt;/code&gt;, this de-biases the image with the help of a bias frame, it has a mutating version as well which de-biases the image in place.&lt;/p&gt;

&lt;p&gt;Next comes &lt;code class="language-plaintext highlighter-rouge"&gt;subtract_overscan&lt;/code&gt;, every CCD plate has some region which is unexposed to light and this is called overscan region. For pre-processing average of this region has to be obtained (there are models as well, that can fit into this region PS: model part has to be implemented later) and then subtracted from the whole image. It also has a mutating variant clubbed together.&lt;/p&gt;

&lt;p&gt;Next in line was &lt;code class="language-plaintext highlighter-rouge"&gt;flat_correct&lt;/code&gt;, this method removes the effect of variations in pixel to pixel sensitivity of detectors and by distortions in the optical path. The interesting point I learned while implementing this is fused broadcasting, believe me Julia keeps on blowing my mind with its speed and succinct syntaxes.&lt;/p&gt;

&lt;p&gt;Next, I implemented some basic functionalities for modifying the image sizes i.e. &lt;code class="language-plaintext highlighter-rouge"&gt;trim&lt;/code&gt; and &lt;code class="language-plaintext highlighter-rouge"&gt;crop&lt;/code&gt;. They are not much different but they are different, let me explain! Trimming is instructing the computer to remove some parts from the image, whereas cropping is instructing the computer to keep a certain part in the image (Yes, that‚Äôs the difference!). Sound‚Äôs pretty similar, right? The implementations were not that similar, &lt;code class="language-plaintext highlighter-rouge"&gt;crop&lt;/code&gt; was a bit tricky as compared to &lt;code class="language-plaintext highlighter-rouge"&gt;trim&lt;/code&gt; (check out the source code to find the difference). These functions are inherently non-mutating type, but I have also implemented a version of &lt;code class="language-plaintext highlighter-rouge"&gt;crop&lt;/code&gt; as &lt;code class="language-plaintext highlighter-rouge"&gt;cropview&lt;/code&gt;, this returns the &lt;code class="language-plaintext highlighter-rouge"&gt;view&lt;/code&gt; of the passed array. Mutating the &lt;code class="language-plaintext highlighter-rouge"&gt;view&lt;/code&gt; will mutate the initial frame passed, an analogous version for &lt;code class="language-plaintext highlighter-rouge"&gt;trim&lt;/code&gt; here is &lt;code class="language-plaintext highlighter-rouge"&gt;trimview&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Next in line was the function &lt;code class="language-plaintext highlighter-rouge"&gt;combine&lt;/code&gt;, it basically takes a variable number of frames, stacks them together, and then finally combines them using medians (users can also have their custom combining functions).&lt;/p&gt;

&lt;p&gt;Okay, this one is last, &lt;code class="language-plaintext highlighter-rouge"&gt;subtract_dark&lt;/code&gt;, a way to reduce image noise in photographs shot with long exposure times, at high ISO sensor sensitivity, or at high temperatures. It takes advantage of the fact that two components of image noise, dark current and fixed-pattern noise, are the same from shot to shot. This function also has a mutating version clubbed along with it.&lt;/p&gt;

&lt;h3 id="hmmm-interesting-whats-next"&gt;&lt;em&gt;Hmmm, interesting‚Ä¶ What‚Äôs next?&lt;/em&gt;&lt;/h3&gt;

&lt;p&gt;Wait, it‚Äôs not yet over! I have also implemented these functions to interface directly with &lt;code class="language-plaintext highlighter-rouge"&gt;FITS&lt;/code&gt; files and &lt;code class="language-plaintext highlighter-rouge"&gt;ImageHDU&lt;/code&gt; (an element of the &lt;code class="language-plaintext highlighter-rouge"&gt;FITS&lt;/code&gt; files), putting it simply, a user can load the data (stored in &lt;code class="language-plaintext highlighter-rouge"&gt;FITS&lt;/code&gt; format) directly from the disk and then can play with all these functions!&lt;/p&gt;

&lt;h3 id="okay-cool-so-whats-next-do-you-still-have-something-in-the-pipeline"&gt;&lt;em&gt;Okay, cool! So what‚Äôs next? Do you still have something in the pipeline?&lt;/em&gt;&lt;/h3&gt;

&lt;p&gt;Yes, the combine function still needs to be interfaced with &lt;code class="language-plaintext highlighter-rouge"&gt;FITS&lt;/code&gt; files, and once done, I will go for a release of the package. The next steps would be user-friendly processing pipelines, iterator reductions, and lot‚Äôs of documentation to be packed up together with the package.&lt;/p&gt;

&lt;p&gt;Stay tuned to know more!&lt;/p&gt;

&lt;p&gt;-sl&lt;/p&gt;&lt;/div&gt;</description><category>JuliaAstro</category><guid>http://openastronomy.org/Universe_OA/posts/2020/06/20200615_1804_siddharthlal25/</guid><pubDate>Mon, 15 Jun 2020 17:04:56 GMT</pubDate></item></channel></rss>